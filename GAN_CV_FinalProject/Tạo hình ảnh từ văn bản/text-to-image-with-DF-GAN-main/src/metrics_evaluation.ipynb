{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "occupied-findings",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "quiet-december",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "needed-honor",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_cwd = os.getcwd()\n",
    "src_path = '/'.join(current_cwd.split('/')[:-1])\n",
    "sys.path.append(src_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "primary-vatican",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'sqrtm' from 'numpy.linalg' (c:\\users\\admin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\linalg\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_23628\\958869973.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfunctional\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mF\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mlinalg\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mnumpy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlinalg\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0msqrtm\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      7\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mscipy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstats\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mentropy\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfunctional\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0madaptive_avg_pool2d\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'sqrtm' from 'numpy.linalg' (c:\\users\\admin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\linalg\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from numpy import linalg\n",
    "from numpy.linalg import sqrtm\n",
    "from scipy.stats import entropy\n",
    "from torch.nn.functional import adaptive_avg_pool2d\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sample import prepare_data, generate_images\n",
    "from src.generator.model import Generator\n",
    "from src.text_encoder.model import RNNEncoder\n",
    "from utils import create_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-blond",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-summer",
   "metadata": {},
   "source": [
    "# Inception model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-poker",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionV3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.device = f'cuda:{0}' if torch.cuda.is_available() else 'cpu'\n",
    "        self.model = torch.hub.load('pytorch/vision:v0.6.0', 'inception_v3', pretrained=True).to(self.device)\n",
    "        print(self.model.fc)\n",
    "        self.linear = self.model.fc\n",
    "        self.model.fc, self.model.dropout = [nn.Sequential()] * 2\n",
    "      \n",
    "    @torch.no_grad()\n",
    "    def get_last_layer(self, x):\n",
    "        x = F.interpolate(x, size=300, mode='bilinear', align_corners=False, recompute_scale_factor=False)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-symphony",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = InceptionV3().to(device)\n",
    "classifier = classifier.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-tooth",
   "metadata": {},
   "source": [
    "# Dataset + DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-merchant",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "test_loader = create_loader(256, batch_size, \"../data\", \"test\")\n",
    "n_words = test_loader.dataset.n_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-ceiling",
   "metadata": {},
   "source": [
    "# Generator + Text Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-tamil",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(n_channels=32, latent_dim=100).to(device)\n",
    "generator.load_state_dict(torch.load(\"../gen_weights/gen_epoch_310.pth\", map_location=device))\n",
    "generator = generator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-mortality",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_encoder = RNNEncoder.load(\"../text_encoder_weights/text_encoder200.pth\", n_words)\n",
    "text_encoder.to(device)\n",
    "\n",
    "for p in text_encoder.parameters():\n",
    "    p.requires_grad = False\n",
    "text_encoder = text_encoder.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-turtle",
   "metadata": {},
   "source": [
    "# FID calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fid(repr1, repr2):\n",
    "    # shape of reprs: (-1, embed_dim)\n",
    "    \n",
    "    # shape of mus: (embed_dim, )\n",
    "    mu_r, mu_g = np.mean(repr1, axis=0), np.mean(repr2, axis=0)\n",
    "    # rowvar=False:\n",
    "    #     each column represents a variable, while the rows contain observations\n",
    "    # shape of sigmas: (embed_dim, embed_dim)\n",
    "    sigma_r, sigma_g = np.cov(repr1, rowvar=False), np.cov(repr2, rowvar=False)\n",
    "    \n",
    "    diff = mu_r - mu_g\n",
    "    diff_square_norm = diff.dot(diff)\n",
    "    \n",
    "    product = sigma_r.dot(sigma_g)\n",
    "    sqrt_product, _ = sqrtm(product, disp=False)\n",
    "    \n",
    "    # np.isfinite:\n",
    "    #     Test element-wise for finiteness \n",
    "    #     (not infinity and not Not a Number)\n",
    "    if not np.isfinite(sqrt_product).all():\n",
    "        eye_matrix = np.eye(sigma_r.shape[0]) * 1e-8\n",
    "        sqrt_product = linalg.sqrtm((sigma_r + eye_matrix).dot(sigma_g + eye_matrix))\n",
    "    \n",
    "    # np.iscomplexobj:\n",
    "    #     Check for a complex type or an array of complex numbers.\n",
    "    #     The return value, True if x is of a complex type\n",
    "    #     or has at least one complex element.\n",
    "    if np.iscomplexobj(sqrt_product):\n",
    "        sqrt_product = sqrt_product.real\n",
    "\n",
    "    fid = diff_square_norm + np.trace(sigma_r + sigma_g - 2 * sqrt_product)\n",
    "    \n",
    "    return fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-castle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_representations():\n",
    "    real_reprs = np.zeros((len(test_loader) * batch_size, 2048))\n",
    "    fake_reprs = np.zeros((len(test_loader) * batch_size, 2048))\n",
    "    \n",
    "    for i, batch in enumerate(tqdm(test_loader, desc=\"Build representations\")):\n",
    "        images, captions, captions_len, file_names = prepare_data(batch, device)\n",
    "        sent_emb = text_encoder(captions, captions_len).detach()\n",
    "\n",
    "        fake_images = generate_images(generator, sent_emb, device)\n",
    "\n",
    "        clf_out_real = classifier.get_last_layer(images)\n",
    "        clf_out_fake = classifier.get_last_layer(fake_images)\n",
    "\n",
    "\n",
    "        real_reprs[i * batch_size: (i + 1) * batch_size] = clf_out_real\n",
    "        fake_reprs[i * batch_size: (i + 1) * batch_size] = clf_out_fake\n",
    "            \n",
    "    return real_reprs, fake_reprs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-display",
   "metadata": {},
   "source": [
    "## Build representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-simpson",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_values, fake_values = build_representations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-process",
   "metadata": {},
   "source": [
    "## FID value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-variety",
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_value = calculate_fid(real_values, fake_values)\n",
    "print(f\"FID value = {fid_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-attention",
   "metadata": {},
   "source": [
    "# Inception score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-behavior",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_score(reprs, batch_size):\n",
    "    def get_pred(x):\n",
    "        x = classifier.linear(torch.tensor(x, dtype=torch.float))\n",
    "        return F.softmax(x).data.cpu().numpy()\n",
    "\n",
    "\n",
    "    preds = np.zeros((reprs.shape[0], 1000))\n",
    "    \n",
    "    splits = 0\n",
    "    for i in range(0, len(preds), batch_size):\n",
    "        z = get_pred(reprs[i:i + batch_size])\n",
    "        preds[i:i + batch_size] = z\n",
    "        splits += 1\n",
    "    \n",
    "    split_scores = []\n",
    "\n",
    "    for k in range(splits):\n",
    "        part = preds[k * batch_size: (k+1) * batch_size, :]\n",
    "        py = np.mean(part, axis=0)\n",
    "        \n",
    "        scores = []\n",
    "        for i in range(part.shape[0]):\n",
    "            pyx = part[i, :]\n",
    "            scores.append(entropy(pyx, py))\n",
    "            \n",
    "        split_scores.append(np.exp(np.mean(scores)))\n",
    "\n",
    "    return np.mean(split_scores), np.std(split_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-lounge",
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_score(fake_values, batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}