{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6787d60b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-12-04T08:30:14.111915Z",
     "iopub.status.busy": "2022-12-04T08:30:14.110907Z",
     "iopub.status.idle": "2022-12-04T08:30:20.669929Z",
     "shell.execute_reply": "2022-12-04T08:30:20.668830Z"
    },
    "papermill": {
     "duration": 6.567681,
     "end_time": "2022-12-04T08:30:20.672215",
     "exception": false,
     "start_time": "2022-12-04T08:30:14.104534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized empty Git repository in /kaggle/working/.git/\r\n",
      "remote: Enumerating objects: 34, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (34/34), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (28/28), done.\u001b[K\r\n",
      "remote: Total 34 (delta 3), reused 34 (delta 3), pack-reused 0\u001b[K\r\n",
      "Unpacking objects: 100% (34/34), 16.33 MiB | 7.61 MiB/s, done.\r\n",
      "From https://github.com/ttbb0802/SRGAN\r\n",
      " * branch            main       -> FETCH_HEAD\r\n",
      " * [new branch]      main       -> origin/main\r\n"
     ]
    }
   ],
   "source": [
    "!git init\n",
    "!git remote add origin https://github.com/ttbb0802/SRGAN.git\n",
    "!git pull origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb8f8279",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T08:30:20.683504Z",
     "iopub.status.busy": "2022-12-04T08:30:20.682660Z",
     "iopub.status.idle": "2022-12-04T08:35:07.836130Z",
     "shell.execute_reply": "2022-12-04T08:35:07.834842Z"
    },
    "papermill": {
     "duration": 287.16144,
     "end_time": "2022-12-04T08:35:07.838489",
     "exception": false,
     "start_time": "2022-12-04T08:30:20.677049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-12-04 08:30:21--  https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\r\n",
      "Resolving data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)... 129.132.52.178, 2001:67c:10ec:36c2::178\r\n",
      "Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.178|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 3530603713 (3.3G) [application/zip]\r\n",
      "Saving to: ‘DIV2K_train_HR.zip’\r\n",
      "\r\n",
      "DIV2K_train_HR.zip  100%[===================>]   3.29G  12.3MB/s    in 4m 45s  \r\n",
      "\r\n",
      "2022-12-04 08:35:07 (11.8 MB/s) - ‘DIV2K_train_HR.zip’ saved [3530603713/3530603713]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51d64e1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T08:35:07.978389Z",
     "iopub.status.busy": "2022-12-04T08:35:07.977556Z",
     "iopub.status.idle": "2022-12-04T08:35:48.093283Z",
     "shell.execute_reply": "2022-12-04T08:35:48.092106Z"
    },
    "papermill": {
     "duration": 40.187161,
     "end_time": "2022-12-04T08:35:48.095682",
     "exception": false,
     "start_time": "2022-12-04T08:35:07.908521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-12-04 08:35:08--  https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_valid_HR.zip\r\n",
      "Resolving data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)... 129.132.52.178, 2001:67c:10ec:36c2::178\r\n",
      "Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.178|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 448993893 (428M) [application/zip]\r\n",
      "Saving to: ‘DIV2K_valid_HR.zip’\r\n",
      "\r\n",
      "DIV2K_valid_HR.zip  100%[===================>] 428.19M  11.9MB/s    in 38s     \r\n",
      "\r\n",
      "2022-12-04 08:35:47 (11.3 MB/s) - ‘DIV2K_valid_HR.zip’ saved [448993893/448993893]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_valid_HR.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b113ab1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T08:35:48.244454Z",
     "iopub.status.busy": "2022-12-04T08:35:48.243445Z",
     "iopub.status.idle": "2022-12-04T08:35:52.574961Z",
     "shell.execute_reply": "2022-12-04T08:35:52.573000Z"
    },
    "papermill": {
     "duration": 4.410031,
     "end_time": "2022-12-04T08:35:52.579020",
     "exception": false,
     "start_time": "2022-12-04T08:35:48.168989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ./DIV2K_valid_HR.zip\r\n",
      "   creating: DIV2K_valid_HR/\r\n",
      "  inflating: DIV2K_valid_HR/0897.png  \r\n",
      "  inflating: DIV2K_valid_HR/0887.png  \r\n",
      "  inflating: DIV2K_valid_HR/0806.png  \r\n",
      "  inflating: DIV2K_valid_HR/0834.png  \r\n",
      "  inflating: DIV2K_valid_HR/0896.png  \r\n",
      "  inflating: DIV2K_valid_HR/0881.png  \r\n",
      "  inflating: DIV2K_valid_HR/0828.png  \r\n",
      "  inflating: DIV2K_valid_HR/0833.png  \r\n",
      "  inflating: DIV2K_valid_HR/0877.png  \r\n",
      "  inflating: DIV2K_valid_HR/0826.png  \r\n",
      "  inflating: DIV2K_valid_HR/0879.png  \r\n",
      "  inflating: DIV2K_valid_HR/0812.png  \r\n",
      "  inflating: DIV2K_valid_HR/0809.png  \r\n",
      "  inflating: DIV2K_valid_HR/0865.png  \r\n",
      "  inflating: DIV2K_valid_HR/0882.png  \r\n",
      "  inflating: DIV2K_valid_HR/0830.png  \r\n",
      "  inflating: DIV2K_valid_HR/0892.png  \r\n",
      "  inflating: DIV2K_valid_HR/0859.png  \r\n",
      "  inflating: DIV2K_valid_HR/0858.png  \r\n",
      "  inflating: DIV2K_valid_HR/0816.png  \r\n",
      "  inflating: DIV2K_valid_HR/0836.png  \r\n",
      "  inflating: DIV2K_valid_HR/0857.png  \r\n",
      "  inflating: DIV2K_valid_HR/0824.png  \r\n",
      "  inflating: DIV2K_valid_HR/0823.png  \r\n",
      "  inflating: DIV2K_valid_HR/0810.png  \r\n",
      "  inflating: DIV2K_valid_HR/0900.png  \r\n",
      "  inflating: DIV2K_valid_HR/0884.png  \r\n",
      "  inflating: DIV2K_valid_HR/0890.png  \r\n",
      "  inflating: DIV2K_valid_HR/0835.png  \r\n",
      "  inflating: DIV2K_valid_HR/0848.png  \r\n",
      "  inflating: DIV2K_valid_HR/0869.png  \r\n",
      "  inflating: DIV2K_valid_HR/0878.png  \r\n",
      "  inflating: DIV2K_valid_HR/0860.png  \r\n",
      "  inflating: DIV2K_valid_HR/0851.png  \r\n",
      "  inflating: DIV2K_valid_HR/0870.png  \r\n",
      "  inflating: DIV2K_valid_HR/0867.png  \r\n",
      "  inflating: DIV2K_valid_HR/0898.png  \r\n",
      "  inflating: DIV2K_valid_HR/0818.png  \r\n",
      "  inflating: DIV2K_valid_HR/0814.png  \r\n",
      "  inflating: DIV2K_valid_HR/0895.png  \r\n",
      "  inflating: DIV2K_valid_HR/0856.png  \r\n",
      "  inflating: DIV2K_valid_HR/0891.png  \r\n",
      "  inflating: DIV2K_valid_HR/0829.png  \r\n",
      "  inflating: DIV2K_valid_HR/0825.png  \r\n",
      "  inflating: DIV2K_valid_HR/0853.png  \r\n",
      "  inflating: DIV2K_valid_HR/0894.png  \r\n",
      "  inflating: DIV2K_valid_HR/0863.png  \r\n",
      "  inflating: DIV2K_valid_HR/0883.png  \r\n",
      "  inflating: DIV2K_valid_HR/0822.png  \r\n",
      "  inflating: DIV2K_valid_HR/0837.png  \r\n",
      "  inflating: DIV2K_valid_HR/0849.png  \r\n",
      "  inflating: DIV2K_valid_HR/0899.png  \r\n",
      "  inflating: DIV2K_valid_HR/0807.png  \r\n",
      "  inflating: DIV2K_valid_HR/0864.png  \r\n",
      "  inflating: DIV2K_valid_HR/0845.png  \r\n",
      "  inflating: DIV2K_valid_HR/0871.png  \r\n",
      "  inflating: DIV2K_valid_HR/0804.png  \r\n",
      "  inflating: DIV2K_valid_HR/0815.png  \r\n",
      "  inflating: DIV2K_valid_HR/0813.png  \r\n",
      "  inflating: DIV2K_valid_HR/0868.png  \r\n",
      "  inflating: DIV2K_valid_HR/0893.png  \r\n",
      "  inflating: DIV2K_valid_HR/0876.png  \r\n",
      "  inflating: DIV2K_valid_HR/0889.png  \r\n",
      "  inflating: DIV2K_valid_HR/0843.png  \r\n",
      "  inflating: DIV2K_valid_HR/0862.png  \r\n",
      "  inflating: DIV2K_valid_HR/0875.png  \r\n",
      "  inflating: DIV2K_valid_HR/0885.png  \r\n",
      "  inflating: DIV2K_valid_HR/0866.png  \r\n",
      "  inflating: DIV2K_valid_HR/0839.png  \r\n",
      "  inflating: DIV2K_valid_HR/0873.png  \r\n",
      "  inflating: DIV2K_valid_HR/0820.png  \r\n",
      "  inflating: DIV2K_valid_HR/0852.png  \r\n",
      "  inflating: DIV2K_valid_HR/0819.png  \r\n",
      "  inflating: DIV2K_valid_HR/0808.png  \r\n",
      "  inflating: DIV2K_valid_HR/0802.png  \r\n",
      "  inflating: DIV2K_valid_HR/0821.png  \r\n",
      "  inflating: DIV2K_valid_HR/0811.png  \r\n",
      "  inflating: DIV2K_valid_HR/0847.png  \r\n",
      "  inflating: DIV2K_valid_HR/0838.png  \r\n",
      "  inflating: DIV2K_valid_HR/0827.png  \r\n",
      "  inflating: DIV2K_valid_HR/0844.png  \r\n",
      "  inflating: DIV2K_valid_HR/0872.png  \r\n",
      "  inflating: DIV2K_valid_HR/0880.png  \r\n",
      "  inflating: DIV2K_valid_HR/0854.png  \r\n",
      "  inflating: DIV2K_valid_HR/0831.png  \r\n",
      "  inflating: DIV2K_valid_HR/0841.png  \r\n",
      "  inflating: DIV2K_valid_HR/0832.png  \r\n",
      "  inflating: DIV2K_valid_HR/0801.png  \r\n",
      "  inflating: DIV2K_valid_HR/0805.png  \r\n",
      "  inflating: DIV2K_valid_HR/0888.png  \r\n",
      "  inflating: DIV2K_valid_HR/0861.png  \r\n",
      "  inflating: DIV2K_valid_HR/0817.png  \r\n",
      "  inflating: DIV2K_valid_HR/0803.png  \r\n",
      "  inflating: DIV2K_valid_HR/0842.png  \r\n",
      "  inflating: DIV2K_valid_HR/0855.png  \r\n",
      "  inflating: DIV2K_valid_HR/0840.png  \r\n",
      "  inflating: DIV2K_valid_HR/0874.png  \r\n",
      "  inflating: DIV2K_valid_HR/0846.png  \r\n",
      "  inflating: DIV2K_valid_HR/0886.png  \r\n",
      "  inflating: DIV2K_valid_HR/0850.png  \r\n"
     ]
    }
   ],
   "source": [
    "!unzip ./DIV2K_valid_HR.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e79a013e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T08:35:52.756138Z",
     "iopub.status.busy": "2022-12-04T08:35:52.755432Z",
     "iopub.status.idle": "2022-12-04T08:36:21.820356Z",
     "shell.execute_reply": "2022-12-04T08:36:21.819280Z"
    },
    "papermill": {
     "duration": 29.143861,
     "end_time": "2022-12-04T08:36:21.822532",
     "exception": false,
     "start_time": "2022-12-04T08:35:52.678671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ./DIV2K_train_HR.zip\r\n",
      "   creating: DIV2K_train_HR/\r\n",
      "  inflating: DIV2K_train_HR/0103.png  \r\n",
      "  inflating: DIV2K_train_HR/0413.png  \r\n",
      "  inflating: DIV2K_train_HR/0031.png  \r\n",
      "  inflating: DIV2K_train_HR/0660.png  \r\n",
      "  inflating: DIV2K_train_HR/0126.png  \r\n",
      "  inflating: DIV2K_train_HR/0793.png  \r\n",
      "  inflating: DIV2K_train_HR/0764.png  \r\n",
      "  inflating: DIV2K_train_HR/0550.png  \r\n",
      "  inflating: DIV2K_train_HR/0437.png  \r\n",
      "  inflating: DIV2K_train_HR/0374.png  \r\n",
      "  inflating: DIV2K_train_HR/0755.png  \r\n",
      "  inflating: DIV2K_train_HR/0614.png  \r\n",
      "  inflating: DIV2K_train_HR/0646.png  \r\n",
      "  inflating: DIV2K_train_HR/0371.png  \r\n",
      "  inflating: DIV2K_train_HR/0312.png  \r\n",
      "  inflating: DIV2K_train_HR/0108.png  \r\n",
      "  inflating: DIV2K_train_HR/0556.png  \r\n",
      "  inflating: DIV2K_train_HR/0794.png  \r\n",
      "  inflating: DIV2K_train_HR/0722.png  \r\n",
      "  inflating: DIV2K_train_HR/0780.png  \r\n",
      "  inflating: DIV2K_train_HR/0555.png  \r\n",
      "  inflating: DIV2K_train_HR/0439.png  \r\n",
      "  inflating: DIV2K_train_HR/0396.png  \r\n",
      "  inflating: DIV2K_train_HR/0666.png  \r\n",
      "  inflating: DIV2K_train_HR/0254.png  \r\n",
      "  inflating: DIV2K_train_HR/0344.png  \r\n",
      "  inflating: DIV2K_train_HR/0062.png  \r\n",
      "  inflating: DIV2K_train_HR/0657.png  \r\n",
      "  inflating: DIV2K_train_HR/0117.png  \r\n",
      "  inflating: DIV2K_train_HR/0395.png  \r\n",
      "  inflating: DIV2K_train_HR/0015.png  \r\n",
      "  inflating: DIV2K_train_HR/0335.png  \r\n",
      "  inflating: DIV2K_train_HR/0578.png  \r\n",
      "  inflating: DIV2K_train_HR/0142.png  \r\n",
      "  inflating: DIV2K_train_HR/0719.png  \r\n",
      "  inflating: DIV2K_train_HR/0101.png  \r\n",
      "  inflating: DIV2K_train_HR/0579.png  \r\n",
      "  inflating: DIV2K_train_HR/0504.png  \r\n",
      "  inflating: DIV2K_train_HR/0576.png  \r\n",
      "  inflating: DIV2K_train_HR/0590.png  \r\n",
      "  inflating: DIV2K_train_HR/0158.png  \r\n",
      "  inflating: DIV2K_train_HR/0384.png  \r\n",
      "  inflating: DIV2K_train_HR/0795.png  \r\n",
      "  inflating: DIV2K_train_HR/0668.png  \r\n",
      "  inflating: DIV2K_train_HR/0144.png  \r\n",
      "  inflating: DIV2K_train_HR/0642.png  \r\n",
      "  inflating: DIV2K_train_HR/0427.png  \r\n",
      "  inflating: DIV2K_train_HR/0593.png  \r\n",
      "  inflating: DIV2K_train_HR/0080.png  \r\n",
      "  inflating: DIV2K_train_HR/0050.png  \r\n",
      "  inflating: DIV2K_train_HR/0617.png  \r\n",
      "  inflating: DIV2K_train_HR/0608.png  \r\n",
      "  inflating: DIV2K_train_HR/0118.png  \r\n",
      "  inflating: DIV2K_train_HR/0082.png  \r\n",
      "  inflating: DIV2K_train_HR/0788.png  \r\n",
      "  inflating: DIV2K_train_HR/0042.png  \r\n",
      "  inflating: DIV2K_train_HR/0333.png  \r\n",
      "  inflating: DIV2K_train_HR/0346.png  \r\n",
      "  inflating: DIV2K_train_HR/0705.png  \r\n",
      "  inflating: DIV2K_train_HR/0195.png  \r\n",
      "  inflating: DIV2K_train_HR/0671.png  \r\n",
      "  inflating: DIV2K_train_HR/0213.png  \r\n",
      "  inflating: DIV2K_train_HR/0692.png  \r\n",
      "  inflating: DIV2K_train_HR/0253.png  \r\n",
      "  inflating: DIV2K_train_HR/0191.png  \r\n",
      "  inflating: DIV2K_train_HR/0628.png  \r\n",
      "  inflating: DIV2K_train_HR/0354.png  \r\n",
      "  inflating: DIV2K_train_HR/0003.png  \r\n",
      "  inflating: DIV2K_train_HR/0393.png  \r\n",
      "  inflating: DIV2K_train_HR/0336.png  \r\n",
      "  inflating: DIV2K_train_HR/0674.png  \r\n",
      "  inflating: DIV2K_train_HR/0586.png  \r\n",
      "  inflating: DIV2K_train_HR/0074.png  \r\n",
      "  inflating: DIV2K_train_HR/0116.png  \r\n",
      "  inflating: DIV2K_train_HR/0270.png  \r\n",
      "  inflating: DIV2K_train_HR/0376.png  \r\n",
      "  inflating: DIV2K_train_HR/0650.png  \r\n",
      "  inflating: DIV2K_train_HR/0462.png  \r\n",
      "  inflating: DIV2K_train_HR/0046.png  \r\n",
      "  inflating: DIV2K_train_HR/0545.png  \r\n",
      "  inflating: DIV2K_train_HR/0347.png  \r\n",
      "  inflating: DIV2K_train_HR/0187.png  \r\n",
      "  inflating: DIV2K_train_HR/0713.png  \r\n",
      "  inflating: DIV2K_train_HR/0558.png  \r\n",
      "  inflating: DIV2K_train_HR/0319.png  \r\n",
      "  inflating: DIV2K_train_HR/0073.png  \r\n",
      "  inflating: DIV2K_train_HR/0033.png  \r\n",
      "  inflating: DIV2K_train_HR/0207.png  \r\n",
      "  inflating: DIV2K_train_HR/0290.png  \r\n",
      "  inflating: DIV2K_train_HR/0194.png  \r\n",
      "  inflating: DIV2K_train_HR/0246.png  \r\n",
      "  inflating: DIV2K_train_HR/0034.png  \r\n",
      "  inflating: DIV2K_train_HR/0621.png  \r\n",
      "  inflating: DIV2K_train_HR/0768.png  \r\n",
      "  inflating: DIV2K_train_HR/0366.png  \r\n",
      "  inflating: DIV2K_train_HR/0490.png  \r\n",
      "  inflating: DIV2K_train_HR/0471.png  \r\n",
      "  inflating: DIV2K_train_HR/0475.png  \r\n",
      "  inflating: DIV2K_train_HR/0152.png  \r\n",
      "  inflating: DIV2K_train_HR/0636.png  \r\n",
      "  inflating: DIV2K_train_HR/0338.png  \r\n",
      "  inflating: DIV2K_train_HR/0358.png  \r\n",
      "  inflating: DIV2K_train_HR/0523.png  \r\n",
      "  inflating: DIV2K_train_HR/0456.png  \r\n",
      "  inflating: DIV2K_train_HR/0470.png  \r\n",
      "  inflating: DIV2K_train_HR/0522.png  \r\n",
      "  inflating: DIV2K_train_HR/0426.png  \r\n",
      "  inflating: DIV2K_train_HR/0587.png  \r\n",
      "  inflating: DIV2K_train_HR/0465.png  \r\n",
      "  inflating: DIV2K_train_HR/0236.png  \r\n",
      "  inflating: DIV2K_train_HR/0192.png  \r\n",
      "  inflating: DIV2K_train_HR/0458.png  \r\n",
      "  inflating: DIV2K_train_HR/0438.png  \r\n",
      "  inflating: DIV2K_train_HR/0176.png  \r\n",
      "  inflating: DIV2K_train_HR/0016.png  \r\n",
      "  inflating: DIV2K_train_HR/0392.png  \r\n",
      "  inflating: DIV2K_train_HR/0054.png  \r\n",
      "  inflating: DIV2K_train_HR/0063.png  \r\n",
      "  inflating: DIV2K_train_HR/0537.png  \r\n",
      "  inflating: DIV2K_train_HR/0271.png  \r\n",
      "  inflating: DIV2K_train_HR/0409.png  \r\n",
      "  inflating: DIV2K_train_HR/0328.png  \r\n",
      "  inflating: DIV2K_train_HR/0582.png  \r\n",
      "  inflating: DIV2K_train_HR/0532.png  \r\n",
      "  inflating: DIV2K_train_HR/0706.png  \r\n",
      "  inflating: DIV2K_train_HR/0153.png  \r\n",
      "  inflating: DIV2K_train_HR/0401.png  \r\n",
      "  inflating: DIV2K_train_HR/0110.png  \r\n",
      "  inflating: DIV2K_train_HR/0316.png  \r\n",
      "  inflating: DIV2K_train_HR/0069.png  \r\n",
      "  inflating: DIV2K_train_HR/0209.png  \r\n",
      "  inflating: DIV2K_train_HR/0351.png  \r\n",
      "  inflating: DIV2K_train_HR/0433.png  \r\n",
      "  inflating: DIV2K_train_HR/0534.png  \r\n",
      "  inflating: DIV2K_train_HR/0525.png  \r\n",
      "  inflating: DIV2K_train_HR/0353.png  \r\n",
      "  inflating: DIV2K_train_HR/0018.png  \r\n",
      "  inflating: DIV2K_train_HR/0592.png  \r\n",
      "  inflating: DIV2K_train_HR/0041.png  \r\n",
      "  inflating: DIV2K_train_HR/0398.png  \r\n",
      "  inflating: DIV2K_train_HR/0355.png  \r\n",
      "  inflating: DIV2K_train_HR/0492.png  \r\n",
      "  inflating: DIV2K_train_HR/0258.png  \r\n",
      "  inflating: DIV2K_train_HR/0051.png  \r\n",
      "  inflating: DIV2K_train_HR/0339.png  \r\n",
      "  inflating: DIV2K_train_HR/0156.png  \r\n",
      "  inflating: DIV2K_train_HR/0174.png  \r\n",
      "  inflating: DIV2K_train_HR/0526.png  \r\n",
      "  inflating: DIV2K_train_HR/0168.png  \r\n",
      "  inflating: DIV2K_train_HR/0515.png  \r\n",
      "  inflating: DIV2K_train_HR/0289.png  \r\n",
      "  inflating: DIV2K_train_HR/0700.png  \r\n",
      "  inflating: DIV2K_train_HR/0711.png  \r\n",
      "  inflating: DIV2K_train_HR/0317.png  \r\n",
      "  inflating: DIV2K_train_HR/0310.png  \r\n",
      "  inflating: DIV2K_train_HR/0075.png  \r\n",
      "  inflating: DIV2K_train_HR/0533.png  \r\n",
      "  inflating: DIV2K_train_HR/0345.png  \r\n",
      "  inflating: DIV2K_train_HR/0238.png  \r\n",
      "  inflating: DIV2K_train_HR/0493.png  \r\n",
      "  inflating: DIV2K_train_HR/0019.png  \r\n",
      "  inflating: DIV2K_train_HR/0559.png  \r\n",
      "  inflating: DIV2K_train_HR/0268.png  \r\n",
      "  inflating: DIV2K_train_HR/0746.png  \r\n",
      "  inflating: DIV2K_train_HR/0648.png  \r\n",
      "  inflating: DIV2K_train_HR/0112.png  \r\n",
      "  inflating: DIV2K_train_HR/0639.png  \r\n",
      "  inflating: DIV2K_train_HR/0216.png  \r\n",
      "  inflating: DIV2K_train_HR/0170.png  \r\n",
      "  inflating: DIV2K_train_HR/0408.png  \r\n",
      "  inflating: DIV2K_train_HR/0461.png  \r\n",
      "  inflating: DIV2K_train_HR/0774.png  \r\n",
      "  inflating: DIV2K_train_HR/0308.png  \r\n",
      "  inflating: DIV2K_train_HR/0368.png  \r\n",
      "  inflating: DIV2K_train_HR/0341.png  \r\n",
      "  inflating: DIV2K_train_HR/0535.png  \r\n",
      "  inflating: DIV2K_train_HR/0585.png  \r\n",
      "  inflating: DIV2K_train_HR/0004.png  \r\n",
      "  inflating: DIV2K_train_HR/0496.png  \r\n",
      "  inflating: DIV2K_train_HR/0662.png  \r\n",
      "  inflating: DIV2K_train_HR/0173.png  \r\n",
      "  inflating: DIV2K_train_HR/0200.png  \r\n",
      "  inflating: DIV2K_train_HR/0752.png  \r\n",
      "  inflating: DIV2K_train_HR/0106.png  \r\n",
      "  inflating: DIV2K_train_HR/0520.png  \r\n",
      "  inflating: DIV2K_train_HR/0519.png  \r\n",
      "  inflating: DIV2K_train_HR/0157.png  \r\n",
      "  inflating: DIV2K_train_HR/0552.png  \r\n",
      "  inflating: DIV2K_train_HR/0735.png  \r\n",
      "  inflating: DIV2K_train_HR/0362.png  \r\n",
      "  inflating: DIV2K_train_HR/0410.png  \r\n",
      "  inflating: DIV2K_train_HR/0286.png  \r\n",
      "  inflating: DIV2K_train_HR/0627.png  \r\n",
      "  inflating: DIV2K_train_HR/0557.png  \r\n",
      "  inflating: DIV2K_train_HR/0266.png  \r\n",
      "  inflating: DIV2K_train_HR/0252.png  \r\n",
      "  inflating: DIV2K_train_HR/0206.png  \r\n",
      "  inflating: DIV2K_train_HR/0330.png  \r\n",
      "  inflating: DIV2K_train_HR/0088.png  \r\n",
      "  inflating: DIV2K_train_HR/0728.png  \r\n",
      "  inflating: DIV2K_train_HR/0641.png  \r\n",
      "  inflating: DIV2K_train_HR/0350.png  \r\n",
      "  inflating: DIV2K_train_HR/0083.png  \r\n",
      "  inflating: DIV2K_train_HR/0682.png  \r\n",
      "  inflating: DIV2K_train_HR/0549.png  \r\n",
      "  inflating: DIV2K_train_HR/0564.png  \r\n",
      "  inflating: DIV2K_train_HR/0476.png  \r\n",
      "  inflating: DIV2K_train_HR/0760.png  \r\n",
      "  inflating: DIV2K_train_HR/0629.png  \r\n",
      "  inflating: DIV2K_train_HR/0630.png  \r\n",
      "  inflating: DIV2K_train_HR/0032.png  \r\n",
      "  inflating: DIV2K_train_HR/0581.png  \r\n",
      "  inflating: DIV2K_train_HR/0056.png  \r\n",
      "  inflating: DIV2K_train_HR/0040.png  \r\n",
      "  inflating: DIV2K_train_HR/0169.png  \r\n",
      "  inflating: DIV2K_train_HR/0400.png  \r\n",
      "  inflating: DIV2K_train_HR/0172.png  \r\n",
      "  inflating: DIV2K_train_HR/0182.png  \r\n",
      "  inflating: DIV2K_train_HR/0269.png  \r\n",
      "  inflating: DIV2K_train_HR/0612.png  \r\n",
      "  inflating: DIV2K_train_HR/0649.png  \r\n",
      "  inflating: DIV2K_train_HR/0311.png  \r\n",
      "  inflating: DIV2K_train_HR/0723.png  \r\n",
      "  inflating: DIV2K_train_HR/0166.png  \r\n",
      "  inflating: DIV2K_train_HR/0155.png  \r\n",
      "  inflating: DIV2K_train_HR/0072.png  \r\n",
      "  inflating: DIV2K_train_HR/0149.png  \r\n",
      "  inflating: DIV2K_train_HR/0425.png  \r\n",
      "  inflating: DIV2K_train_HR/0715.png  \r\n",
      "  inflating: DIV2K_train_HR/0670.png  \r\n",
      "  inflating: DIV2K_train_HR/0460.png  \r\n",
      "  inflating: DIV2K_train_HR/0748.png  \r\n",
      "  inflating: DIV2K_train_HR/0147.png  \r\n",
      "  inflating: DIV2K_train_HR/0602.png  \r\n",
      "  inflating: DIV2K_train_HR/0610.png  \r\n",
      "  inflating: DIV2K_train_HR/0479.png  \r\n",
      "  inflating: DIV2K_train_HR/0603.png  \r\n",
      "  inflating: DIV2K_train_HR/0043.png  \r\n",
      "  inflating: DIV2K_train_HR/0190.png  \r\n",
      "  inflating: DIV2K_train_HR/0503.png  \r\n",
      "  inflating: DIV2K_train_HR/0055.png  \r\n",
      "  inflating: DIV2K_train_HR/0337.png  \r\n",
      "  inflating: DIV2K_train_HR/0453.png  \r\n",
      "  inflating: DIV2K_train_HR/0219.png  \r\n",
      "  inflating: DIV2K_train_HR/0548.png  \r\n",
      "  inflating: DIV2K_train_HR/0661.png  \r\n",
      "  inflating: DIV2K_train_HR/0718.png  \r\n",
      "  inflating: DIV2K_train_HR/0489.png  \r\n",
      "  inflating: DIV2K_train_HR/0775.png  \r\n",
      "  inflating: DIV2K_train_HR/0323.png  \r\n",
      "  inflating: DIV2K_train_HR/0664.png  \r\n",
      "  inflating: DIV2K_train_HR/0002.png  \r\n",
      "  inflating: DIV2K_train_HR/0127.png  \r\n",
      "  inflating: DIV2K_train_HR/0322.png  \r\n",
      "  inflating: DIV2K_train_HR/0640.png  \r\n",
      "  inflating: DIV2K_train_HR/0473.png  \r\n",
      "  inflating: DIV2K_train_HR/0730.png  \r\n",
      "  inflating: DIV2K_train_HR/0008.png  \r\n",
      "  inflating: DIV2K_train_HR/0486.png  \r\n",
      "  inflating: DIV2K_train_HR/0597.png  \r\n",
      "  inflating: DIV2K_train_HR/0064.png  \r\n",
      "  inflating: DIV2K_train_HR/0068.png  \r\n",
      "  inflating: DIV2K_train_HR/0510.png  \r\n",
      "  inflating: DIV2K_train_HR/0594.png  \r\n",
      "  inflating: DIV2K_train_HR/0685.png  \r\n",
      "  inflating: DIV2K_train_HR/0497.png  \r\n",
      "  inflating: DIV2K_train_HR/0637.png  \r\n",
      "  inflating: DIV2K_train_HR/0332.png  \r\n",
      "  inflating: DIV2K_train_HR/0208.png  \r\n",
      "  inflating: DIV2K_train_HR/0241.png  \r\n",
      "  inflating: DIV2K_train_HR/0201.png  \r\n",
      "  inflating: DIV2K_train_HR/0044.png  \r\n",
      "  inflating: DIV2K_train_HR/0141.png  \r\n",
      "  inflating: DIV2K_train_HR/0381.png  \r\n",
      "  inflating: DIV2K_train_HR/0412.png  \r\n",
      "  inflating: DIV2K_train_HR/0035.png  \r\n",
      "  inflating: DIV2K_train_HR/0049.png  \r\n",
      "  inflating: DIV2K_train_HR/0181.png  \r\n",
      "  inflating: DIV2K_train_HR/0340.png  \r\n",
      "  inflating: DIV2K_train_HR/0272.png  \r\n",
      "  inflating: DIV2K_train_HR/0279.png  \r\n",
      "  inflating: DIV2K_train_HR/0307.png  \r\n",
      "  inflating: DIV2K_train_HR/0733.png  \r\n",
      "  inflating: DIV2K_train_HR/0250.png  \r\n",
      "  inflating: DIV2K_train_HR/0739.png  \r\n",
      "  inflating: DIV2K_train_HR/0654.png  \r\n",
      "  inflating: DIV2K_train_HR/0343.png  \r\n",
      "  inflating: DIV2K_train_HR/0422.png  \r\n",
      "  inflating: DIV2K_train_HR/0297.png  \r\n",
      "  inflating: DIV2K_train_HR/0360.png  \r\n",
      "  inflating: DIV2K_train_HR/0099.png  \r\n",
      "  inflating: DIV2K_train_HR/0541.png  \r\n",
      "  inflating: DIV2K_train_HR/0616.png  \r\n",
      "  inflating: DIV2K_train_HR/0352.png  \r\n",
      "  inflating: DIV2K_train_HR/0092.png  \r\n",
      "  inflating: DIV2K_train_HR/0528.png  \r\n",
      "  inflating: DIV2K_train_HR/0483.png  \r\n",
      "  inflating: DIV2K_train_HR/0631.png  \r\n",
      "  inflating: DIV2K_train_HR/0134.png  \r\n",
      "  inflating: DIV2K_train_HR/0625.png  \r\n",
      "  inflating: DIV2K_train_HR/0530.png  \r\n",
      "  inflating: DIV2K_train_HR/0454.png  \r\n",
      "  inflating: DIV2K_train_HR/0624.png  \r\n",
      "  inflating: DIV2K_train_HR/0501.png  \r\n",
      "  inflating: DIV2K_train_HR/0038.png  \r\n",
      "  inflating: DIV2K_train_HR/0365.png  \r\n",
      "  inflating: DIV2K_train_HR/0789.png  \r\n",
      "  inflating: DIV2K_train_HR/0010.png  \r\n",
      "  inflating: DIV2K_train_HR/0543.png  \r\n",
      "  inflating: DIV2K_train_HR/0635.png  \r\n",
      "  inflating: DIV2K_train_HR/0418.png  \r\n",
      "  inflating: DIV2K_train_HR/0159.png  \r\n",
      "  inflating: DIV2K_train_HR/0689.png  \r\n",
      "  inflating: DIV2K_train_HR/0429.png  \r\n",
      "  inflating: DIV2K_train_HR/0276.png  \r\n",
      "  inflating: DIV2K_train_HR/0255.png  \r\n",
      "  inflating: DIV2K_train_HR/0293.png  \r\n",
      "  inflating: DIV2K_train_HR/0327.png  \r\n",
      "  inflating: DIV2K_train_HR/0488.png  \r\n",
      "  inflating: DIV2K_train_HR/0244.png  \r\n",
      "  inflating: DIV2K_train_HR/0721.png  \r\n",
      "  inflating: DIV2K_train_HR/0652.png  \r\n",
      "  inflating: DIV2K_train_HR/0779.png  \r\n",
      "  inflating: DIV2K_train_HR/0687.png  \r\n",
      "  inflating: DIV2K_train_HR/0326.png  \r\n",
      "  inflating: DIV2K_train_HR/0161.png  \r\n",
      "  inflating: DIV2K_train_HR/0498.png  \r\n",
      "  inflating: DIV2K_train_HR/0264.png  \r\n",
      "  inflating: DIV2K_train_HR/0136.png  \r\n",
      "  inflating: DIV2K_train_HR/0006.png  \r\n",
      "  inflating: DIV2K_train_HR/0741.png  \r\n",
      "  inflating: DIV2K_train_HR/0421.png  \r\n",
      "  inflating: DIV2K_train_HR/0229.png  \r\n",
      "  inflating: DIV2K_train_HR/0373.png  \r\n",
      "  inflating: DIV2K_train_HR/0703.png  \r\n",
      "  inflating: DIV2K_train_HR/0516.png  \r\n",
      "  inflating: DIV2K_train_HR/0234.png  \r\n",
      "  inflating: DIV2K_train_HR/0405.png  \r\n",
      "  inflating: DIV2K_train_HR/0763.png  \r\n",
      "  inflating: DIV2K_train_HR/0619.png  \r\n",
      "  inflating: DIV2K_train_HR/0138.png  \r\n",
      "  inflating: DIV2K_train_HR/0513.png  \r\n",
      "  inflating: DIV2K_train_HR/0432.png  \r\n",
      "  inflating: DIV2K_train_HR/0177.png  \r\n",
      "  inflating: DIV2K_train_HR/0017.png  \r\n",
      "  inflating: DIV2K_train_HR/0736.png  \r\n",
      "  inflating: DIV2K_train_HR/0459.png  \r\n",
      "  inflating: DIV2K_train_HR/0505.png  \r\n",
      "  inflating: DIV2K_train_HR/0397.png  \r\n",
      "  inflating: DIV2K_train_HR/0591.png  \r\n",
      "  inflating: DIV2K_train_HR/0196.png  \r\n",
      "  inflating: DIV2K_train_HR/0724.png  \r\n",
      "  inflating: DIV2K_train_HR/0740.png  \r\n",
      "  inflating: DIV2K_train_HR/0223.png  \r\n",
      "  inflating: DIV2K_train_HR/0442.png  \r\n",
      "  inflating: DIV2K_train_HR/0165.png  \r\n",
      "  inflating: DIV2K_train_HR/0302.png  \r\n",
      "  inflating: DIV2K_train_HR/0386.png  \r\n",
      "  inflating: DIV2K_train_HR/0601.png  \r\n",
      "  inflating: DIV2K_train_HR/0370.png  \r\n",
      "  inflating: DIV2K_train_HR/0647.png  \r\n",
      "  inflating: DIV2K_train_HR/0267.png  \r\n",
      "  inflating: DIV2K_train_HR/0380.png  \r\n",
      "  inflating: DIV2K_train_HR/0441.png  \r\n",
      "  inflating: DIV2K_train_HR/0037.png  \r\n",
      "  inflating: DIV2K_train_HR/0678.png  \r\n",
      "  inflating: DIV2K_train_HR/0304.png  \r\n",
      "  inflating: DIV2K_train_HR/0494.png  \r\n",
      "  inflating: DIV2K_train_HR/0028.png  \r\n",
      "  inflating: DIV2K_train_HR/0613.png  \r\n",
      "  inflating: DIV2K_train_HR/0257.png  \r\n",
      "  inflating: DIV2K_train_HR/0100.png  \r\n",
      "  inflating: DIV2K_train_HR/0097.png  \r\n",
      "  inflating: DIV2K_train_HR/0604.png  \r\n",
      "  inflating: DIV2K_train_HR/0023.png  \r\n",
      "  inflating: DIV2K_train_HR/0782.png  \r\n",
      "  inflating: DIV2K_train_HR/0446.png  \r\n",
      "  inflating: DIV2K_train_HR/0378.png  \r\n",
      "  inflating: DIV2K_train_HR/0411.png  \r\n",
      "  inflating: DIV2K_train_HR/0320.png  \r\n",
      "  inflating: DIV2K_train_HR/0390.png  \r\n",
      "  inflating: DIV2K_train_HR/0148.png  \r\n",
      "  inflating: DIV2K_train_HR/0577.png  \r\n",
      "  inflating: DIV2K_train_HR/0684.png  \r\n",
      "  inflating: DIV2K_train_HR/0595.png  \r\n",
      "  inflating: DIV2K_train_HR/0765.png  \r\n",
      "  inflating: DIV2K_train_HR/0203.png  \r\n",
      "  inflating: DIV2K_train_HR/0288.png  \r\n",
      "  inflating: DIV2K_train_HR/0058.png  \r\n",
      "  inflating: DIV2K_train_HR/0790.png  \r\n",
      "  inflating: DIV2K_train_HR/0605.png  \r\n",
      "  inflating: DIV2K_train_HR/0248.png  \r\n",
      "  inflating: DIV2K_train_HR/0467.png  \r\n",
      "  inflating: DIV2K_train_HR/0210.png  \r\n",
      "  inflating: DIV2K_train_HR/0517.png  \r\n",
      "  inflating: DIV2K_train_HR/0707.png  \r\n",
      "  inflating: DIV2K_train_HR/0566.png  \r\n",
      "  inflating: DIV2K_train_HR/0224.png  \r\n",
      "  inflating: DIV2K_train_HR/0114.png  \r\n",
      "  inflating: DIV2K_train_HR/0761.png  \r\n",
      "  inflating: DIV2K_train_HR/0468.png  \r\n",
      "  inflating: DIV2K_train_HR/0716.png  \r\n",
      "  inflating: DIV2K_train_HR/0420.png  \r\n",
      "  inflating: DIV2K_train_HR/0669.png  \r\n",
      "  inflating: DIV2K_train_HR/0375.png  \r\n",
      "  inflating: DIV2K_train_HR/0140.png  \r\n",
      "  inflating: DIV2K_train_HR/0792.png  \r\n",
      "  inflating: DIV2K_train_HR/0240.png  \r\n",
      "  inflating: DIV2K_train_HR/0546.png  \r\n",
      "  inflating: DIV2K_train_HR/0235.png  \r\n",
      "  inflating: DIV2K_train_HR/0077.png  \r\n",
      "  inflating: DIV2K_train_HR/0260.png  \r\n",
      "  inflating: DIV2K_train_HR/0212.png  \r\n",
      "  inflating: DIV2K_train_HR/0584.png  \r\n",
      "  inflating: DIV2K_train_HR/0633.png  \r\n",
      "  inflating: DIV2K_train_HR/0060.png  \r\n",
      "  inflating: DIV2K_train_HR/0164.png  \r\n",
      "  inflating: DIV2K_train_HR/0622.png  \r\n",
      "  inflating: DIV2K_train_HR/0105.png  \r\n",
      "  inflating: DIV2K_train_HR/0005.png  \r\n",
      "  inflating: DIV2K_train_HR/0679.png  \r\n",
      "  inflating: DIV2K_train_HR/0089.png  \r\n",
      "  inflating: DIV2K_train_HR/0466.png  \r\n",
      "  inflating: DIV2K_train_HR/0645.png  \r\n",
      "  inflating: DIV2K_train_HR/0301.png  \r\n",
      "  inflating: DIV2K_train_HR/0499.png  \r\n",
      "  inflating: DIV2K_train_HR/0020.png  \r\n",
      "  inflating: DIV2K_train_HR/0070.png  \r\n",
      "  inflating: DIV2K_train_HR/0404.png  \r\n",
      "  inflating: DIV2K_train_HR/0749.png  \r\n",
      "  inflating: DIV2K_train_HR/0770.png  \r\n",
      "  inflating: DIV2K_train_HR/0772.png  \r\n",
      "  inflating: DIV2K_train_HR/0450.png  \r\n",
      "  inflating: DIV2K_train_HR/0120.png  \r\n",
      "  inflating: DIV2K_train_HR/0653.png  \r\n",
      "  inflating: DIV2K_train_HR/0563.png  \r\n",
      "  inflating: DIV2K_train_HR/0171.png  \r\n",
      "  inflating: DIV2K_train_HR/0784.png  \r\n",
      "  inflating: DIV2K_train_HR/0688.png  \r\n",
      "  inflating: DIV2K_train_HR/0045.png  \r\n",
      "  inflating: DIV2K_train_HR/0066.png  \r\n",
      "  inflating: DIV2K_train_HR/0583.png  \r\n",
      "  inflating: DIV2K_train_HR/0632.png  \r\n",
      "  inflating: DIV2K_train_HR/0512.png  \r\n",
      "  inflating: DIV2K_train_HR/0767.png  \r\n",
      "  inflating: DIV2K_train_HR/0623.png  \r\n",
      "  inflating: DIV2K_train_HR/0406.png  \r\n",
      "  inflating: DIV2K_train_HR/0419.png  \r\n",
      "  inflating: DIV2K_train_HR/0273.png  \r\n",
      "  inflating: DIV2K_train_HR/0198.png  \r\n",
      "  inflating: DIV2K_train_HR/0750.png  \r\n",
      "  inflating: DIV2K_train_HR/0220.png  \r\n",
      "  inflating: DIV2K_train_HR/0482.png  \r\n",
      "  inflating: DIV2K_train_HR/0407.png  \r\n",
      "  inflating: DIV2K_train_HR/0704.png  \r\n",
      "  inflating: DIV2K_train_HR/0547.png  \r\n",
      "  inflating: DIV2K_train_HR/0589.png  \r\n",
      "  inflating: DIV2K_train_HR/0012.png  \r\n",
      "  inflating: DIV2K_train_HR/0150.png  \r\n",
      "  inflating: DIV2K_train_HR/0481.png  \r\n",
      "  inflating: DIV2K_train_HR/0357.png  \r\n",
      "  inflating: DIV2K_train_HR/0677.png  \r\n",
      "  inflating: DIV2K_train_HR/0315.png  \r\n",
      "  inflating: DIV2K_train_HR/0394.png  \r\n",
      "  inflating: DIV2K_train_HR/0160.png  \r\n",
      "  inflating: DIV2K_train_HR/0667.png  \r\n",
      "  inflating: DIV2K_train_HR/0568.png  \r\n",
      "  inflating: DIV2K_train_HR/0435.png  \r\n",
      "  inflating: DIV2K_train_HR/0606.png  \r\n",
      "  inflating: DIV2K_train_HR/0464.png  \r\n",
      "  inflating: DIV2K_train_HR/0364.png  \r\n",
      "  inflating: DIV2K_train_HR/0245.png  \r\n",
      "  inflating: DIV2K_train_HR/0508.png  \r\n",
      "  inflating: DIV2K_train_HR/0356.png  \r\n",
      "  inflating: DIV2K_train_HR/0135.png  \r\n",
      "  inflating: DIV2K_train_HR/0146.png  \r\n",
      "  inflating: DIV2K_train_HR/0574.png  \r\n",
      "  inflating: DIV2K_train_HR/0698.png  \r\n",
      "  inflating: DIV2K_train_HR/0222.png  \r\n",
      "  inflating: DIV2K_train_HR/0261.png  \r\n",
      "  inflating: DIV2K_train_HR/0444.png  \r\n",
      "  inflating: DIV2K_train_HR/0078.png  \r\n",
      "  inflating: DIV2K_train_HR/0123.png  \r\n",
      "  inflating: DIV2K_train_HR/0797.png  \r\n",
      "  inflating: DIV2K_train_HR/0274.png  \r\n",
      "  inflating: DIV2K_train_HR/0225.png  \r\n",
      "  inflating: DIV2K_train_HR/0180.png  \r\n",
      "  inflating: DIV2K_train_HR/0325.png  \r\n",
      "  inflating: DIV2K_train_HR/0372.png  \r\n",
      "  inflating: DIV2K_train_HR/0029.png  \r\n",
      "  inflating: DIV2K_train_HR/0318.png  \r\n",
      "  inflating: DIV2K_train_HR/0452.png  \r\n",
      "  inflating: DIV2K_train_HR/0115.png  \r\n",
      "  inflating: DIV2K_train_HR/0423.png  \r\n",
      "  inflating: DIV2K_train_HR/0615.png  \r\n",
      "  inflating: DIV2K_train_HR/0672.png  \r\n",
      "  inflating: DIV2K_train_HR/0231.png  \r\n",
      "  inflating: DIV2K_train_HR/0731.png  \r\n",
      "  inflating: DIV2K_train_HR/0389.png  \r\n",
      "  inflating: DIV2K_train_HR/0680.png  \r\n",
      "  inflating: DIV2K_train_HR/0329.png  \r\n",
      "  inflating: DIV2K_train_HR/0663.png  \r\n",
      "  inflating: DIV2K_train_HR/0659.png  \r\n",
      "  inflating: DIV2K_train_HR/0292.png  \r\n",
      "  inflating: DIV2K_train_HR/0284.png  \r\n",
      "  inflating: DIV2K_train_HR/0133.png  \r\n",
      "  inflating: DIV2K_train_HR/0727.png  \r\n",
      "  inflating: DIV2K_train_HR/0445.png  \r\n",
      "  inflating: DIV2K_train_HR/0139.png  \r\n",
      "  inflating: DIV2K_train_HR/0298.png  \r\n",
      "  inflating: DIV2K_train_HR/0282.png  \r\n",
      "  inflating: DIV2K_train_HR/0778.png  \r\n",
      "  inflating: DIV2K_train_HR/0565.png  \r\n",
      "  inflating: DIV2K_train_HR/0485.png  \r\n",
      "  inflating: DIV2K_train_HR/0495.png  \r\n",
      "  inflating: DIV2K_train_HR/0215.png  \r\n",
      "  inflating: DIV2K_train_HR/0694.png  \r\n",
      "  inflating: DIV2K_train_HR/0321.png  \r\n",
      "  inflating: DIV2K_train_HR/0094.png  \r\n",
      "  inflating: DIV2K_train_HR/0598.png  \r\n",
      "  inflating: DIV2K_train_HR/0430.png  \r\n",
      "  inflating: DIV2K_train_HR/0021.png  \r\n",
      "  inflating: DIV2K_train_HR/0036.png  \r\n",
      "  inflating: DIV2K_train_HR/0188.png  \r\n",
      "  inflating: DIV2K_train_HR/0334.png  \r\n",
      "  inflating: DIV2K_train_HR/0759.png  \r\n",
      "  inflating: DIV2K_train_HR/0217.png  \r\n",
      "  inflating: DIV2K_train_HR/0562.png  \r\n",
      "  inflating: DIV2K_train_HR/0124.png  \r\n",
      "  inflating: DIV2K_train_HR/0690.png  \r\n",
      "  inflating: DIV2K_train_HR/0385.png  \r\n",
      "  inflating: DIV2K_train_HR/0695.png  \r\n",
      "  inflating: DIV2K_train_HR/0708.png  \r\n",
      "  inflating: DIV2K_train_HR/0745.png  \r\n",
      "  inflating: DIV2K_train_HR/0007.png  \r\n",
      "  inflating: DIV2K_train_HR/0226.png  \r\n",
      "  inflating: DIV2K_train_HR/0256.png  \r\n",
      "  inflating: DIV2K_train_HR/0673.png  \r\n",
      "  inflating: DIV2K_train_HR/0451.png  \r\n",
      "  inflating: DIV2K_train_HR/0143.png  \r\n",
      "  inflating: DIV2K_train_HR/0403.png  \r\n",
      "  inflating: DIV2K_train_HR/0125.png  \r\n",
      "  inflating: DIV2K_train_HR/0132.png  \r\n",
      "  inflating: DIV2K_train_HR/0644.png  \r\n",
      "  inflating: DIV2K_train_HR/0796.png  \r\n",
      "  inflating: DIV2K_train_HR/0076.png  \r\n",
      "  inflating: DIV2K_train_HR/0211.png  \r\n",
      "  inflating: DIV2K_train_HR/0676.png  \r\n",
      "  inflating: DIV2K_train_HR/0121.png  \r\n",
      "  inflating: DIV2K_train_HR/0415.png  \r\n",
      "  inflating: DIV2K_train_HR/0536.png  \r\n",
      "  inflating: DIV2K_train_HR/0620.png  \r\n",
      "  inflating: DIV2K_train_HR/0331.png  \r\n",
      "  inflating: DIV2K_train_HR/0277.png  \r\n",
      "  inflating: DIV2K_train_HR/0611.png  \r\n",
      "  inflating: DIV2K_train_HR/0262.png  \r\n",
      "  inflating: DIV2K_train_HR/0305.png  \r\n",
      "  inflating: DIV2K_train_HR/0521.png  \r\n",
      "  inflating: DIV2K_train_HR/0221.png  \r\n",
      "  inflating: DIV2K_train_HR/0699.png  \r\n",
      "  inflating: DIV2K_train_HR/0743.png  \r\n",
      "  inflating: DIV2K_train_HR/0742.png  \r\n",
      "  inflating: DIV2K_train_HR/0111.png  \r\n",
      "  inflating: DIV2K_train_HR/0480.png  \r\n",
      "  inflating: DIV2K_train_HR/0720.png  \r\n",
      "  inflating: DIV2K_train_HR/0402.png  \r\n",
      "  inflating: DIV2K_train_HR/0561.png  \r\n",
      "  inflating: DIV2K_train_HR/0729.png  \r\n",
      "  inflating: DIV2K_train_HR/0296.png  \r\n",
      "  inflating: DIV2K_train_HR/0379.png  \r\n",
      "  inflating: DIV2K_train_HR/0014.png  \r\n",
      "  inflating: DIV2K_train_HR/0714.png  \r\n",
      "  inflating: DIV2K_train_HR/0754.png  \r\n",
      "  inflating: DIV2K_train_HR/0634.png  \r\n",
      "  inflating: DIV2K_train_HR/0725.png  \r\n",
      "  inflating: DIV2K_train_HR/0309.png  \r\n",
      "  inflating: DIV2K_train_HR/0197.png  \r\n",
      "  inflating: DIV2K_train_HR/0039.png  \r\n",
      "  inflating: DIV2K_train_HR/0696.png  \r\n",
      "  inflating: DIV2K_train_HR/0758.png  \r\n",
      "  inflating: DIV2K_train_HR/0599.png  \r\n",
      "  inflating: DIV2K_train_HR/0228.png  \r\n",
      "  inflating: DIV2K_train_HR/0712.png  \r\n",
      "  inflating: DIV2K_train_HR/0539.png  \r\n",
      "  inflating: DIV2K_train_HR/0781.png  \r\n",
      "  inflating: DIV2K_train_HR/0009.png  \r\n",
      "  inflating: DIV2K_train_HR/0145.png  \r\n",
      "  inflating: DIV2K_train_HR/0527.png  \r\n",
      "  inflating: DIV2K_train_HR/0263.png  \r\n",
      "  inflating: DIV2K_train_HR/0122.png  \r\n",
      "  inflating: DIV2K_train_HR/0506.png  \r\n",
      "  inflating: DIV2K_train_HR/0363.png  \r\n",
      "  inflating: DIV2K_train_HR/0249.png  \r\n",
      "  inflating: DIV2K_train_HR/0104.png  \r\n",
      "  inflating: DIV2K_train_HR/0800.png  \r\n",
      "  inflating: DIV2K_train_HR/0214.png  \r\n",
      "  inflating: DIV2K_train_HR/0658.png  \r\n",
      "  inflating: DIV2K_train_HR/0399.png  \r\n",
      "  inflating: DIV2K_train_HR/0572.png  \r\n",
      "  inflating: DIV2K_train_HR/0204.png  \r\n",
      "  inflating: DIV2K_train_HR/0651.png  \r\n",
      "  inflating: DIV2K_train_HR/0061.png  \r\n",
      "  inflating: DIV2K_train_HR/0026.png  \r\n",
      "  inflating: DIV2K_train_HR/0300.png  \r\n",
      "  inflating: DIV2K_train_HR/0162.png  \r\n",
      "  inflating: DIV2K_train_HR/0478.png  \r\n",
      "  inflating: DIV2K_train_HR/0022.png  \r\n",
      "  inflating: DIV2K_train_HR/0079.png  \r\n",
      "  inflating: DIV2K_train_HR/0285.png  \r\n",
      "  inflating: DIV2K_train_HR/0511.png  \r\n",
      "  inflating: DIV2K_train_HR/0025.png  \r\n",
      "  inflating: DIV2K_train_HR/0428.png  \r\n",
      "  inflating: DIV2K_train_HR/0436.png  \r\n",
      "  inflating: DIV2K_train_HR/0324.png  \r\n",
      "  inflating: DIV2K_train_HR/0447.png  \r\n",
      "  inflating: DIV2K_train_HR/0457.png  \r\n",
      "  inflating: DIV2K_train_HR/0424.png  \r\n",
      "  inflating: DIV2K_train_HR/0675.png  \r\n",
      "  inflating: DIV2K_train_HR/0469.png  \r\n",
      "  inflating: DIV2K_train_HR/0090.png  \r\n",
      "  inflating: DIV2K_train_HR/0179.png  \r\n",
      "  inflating: DIV2K_train_HR/0771.png  \r\n",
      "  inflating: DIV2K_train_HR/0431.png  \r\n",
      "  inflating: DIV2K_train_HR/0726.png  \r\n",
      "  inflating: DIV2K_train_HR/0609.png  \r\n",
      "  inflating: DIV2K_train_HR/0184.png  \r\n",
      "  inflating: DIV2K_train_HR/0747.png  \r\n",
      "  inflating: DIV2K_train_HR/0154.png  \r\n",
      "  inflating: DIV2K_train_HR/0391.png  \r\n",
      "  inflating: DIV2K_train_HR/0573.png  \r\n",
      "  inflating: DIV2K_train_HR/0071.png  \r\n",
      "  inflating: DIV2K_train_HR/0798.png  \r\n",
      "  inflating: DIV2K_train_HR/0693.png  \r\n",
      "  inflating: DIV2K_train_HR/0280.png  \r\n",
      "  inflating: DIV2K_train_HR/0414.png  \r\n",
      "  inflating: DIV2K_train_HR/0119.png  \r\n",
      "  inflating: DIV2K_train_HR/0757.png  \r\n",
      "  inflating: DIV2K_train_HR/0762.png  \r\n",
      "  inflating: DIV2K_train_HR/0734.png  \r\n",
      "  inflating: DIV2K_train_HR/0001.png  \r\n",
      "  inflating: DIV2K_train_HR/0265.png  \r\n",
      "  inflating: DIV2K_train_HR/0643.png  \r\n",
      "  inflating: DIV2K_train_HR/0567.png  \r\n",
      "  inflating: DIV2K_train_HR/0130.png  \r\n",
      "  inflating: DIV2K_train_HR/0580.png  \r\n",
      "  inflating: DIV2K_train_HR/0463.png  \r\n",
      "  inflating: DIV2K_train_HR/0218.png  \r\n",
      "  inflating: DIV2K_train_HR/0769.png  \r\n",
      "  inflating: DIV2K_train_HR/0507.png  \r\n",
      "  inflating: DIV2K_train_HR/0013.png  \r\n",
      "  inflating: DIV2K_train_HR/0233.png  \r\n",
      "  inflating: DIV2K_train_HR/0087.png  \r\n",
      "  inflating: DIV2K_train_HR/0093.png  \r\n",
      "  inflating: DIV2K_train_HR/0709.png  \r\n",
      "  inflating: DIV2K_train_HR/0027.png  \r\n",
      "  inflating: DIV2K_train_HR/0570.png  \r\n",
      "  inflating: DIV2K_train_HR/0342.png  \r\n",
      "  inflating: DIV2K_train_HR/0011.png  \r\n",
      "  inflating: DIV2K_train_HR/0287.png  \r\n",
      "  inflating: DIV2K_train_HR/0524.png  \r\n",
      "  inflating: DIV2K_train_HR/0791.png  \r\n",
      "  inflating: DIV2K_train_HR/0701.png  \r\n",
      "  inflating: DIV2K_train_HR/0783.png  \r\n",
      "  inflating: DIV2K_train_HR/0349.png  \r\n",
      "  inflating: DIV2K_train_HR/0766.png  \r\n",
      "  inflating: DIV2K_train_HR/0232.png  \r\n",
      "  inflating: DIV2K_train_HR/0314.png  \r\n",
      "  inflating: DIV2K_train_HR/0303.png  \r\n",
      "  inflating: DIV2K_train_HR/0697.png  \r\n",
      "  inflating: DIV2K_train_HR/0514.png  \r\n",
      "  inflating: DIV2K_train_HR/0377.png  \r\n",
      "  inflating: DIV2K_train_HR/0085.png  \r\n",
      "  inflating: DIV2K_train_HR/0113.png  \r\n",
      "  inflating: DIV2K_train_HR/0540.png  \r\n",
      "  inflating: DIV2K_train_HR/0383.png  \r\n",
      "  inflating: DIV2K_train_HR/0243.png  \r\n",
      "  inflating: DIV2K_train_HR/0086.png  \r\n",
      "  inflating: DIV2K_train_HR/0091.png  \r\n",
      "  inflating: DIV2K_train_HR/0151.png  \r\n",
      "  inflating: DIV2K_train_HR/0502.png  \r\n",
      "  inflating: DIV2K_train_HR/0294.png  \r\n",
      "  inflating: DIV2K_train_HR/0281.png  \r\n",
      "  inflating: DIV2K_train_HR/0656.png  \r\n",
      "  inflating: DIV2K_train_HR/0500.png  \r\n",
      "  inflating: DIV2K_train_HR/0237.png  \r\n",
      "  inflating: DIV2K_train_HR/0387.png  \r\n",
      "  inflating: DIV2K_train_HR/0178.png  \r\n",
      "  inflating: DIV2K_train_HR/0518.png  \r\n",
      "  inflating: DIV2K_train_HR/0239.png  \r\n",
      "  inflating: DIV2K_train_HR/0131.png  \r\n",
      "  inflating: DIV2K_train_HR/0655.png  \r\n",
      "  inflating: DIV2K_train_HR/0417.png  \r\n",
      "  inflating: DIV2K_train_HR/0776.png  \r\n",
      "  inflating: DIV2K_train_HR/0560.png  \r\n",
      "  inflating: DIV2K_train_HR/0737.png  \r\n",
      "  inflating: DIV2K_train_HR/0048.png  \r\n",
      "  inflating: DIV2K_train_HR/0128.png  \r\n",
      "  inflating: DIV2K_train_HR/0052.png  \r\n",
      "  inflating: DIV2K_train_HR/0137.png  \r\n",
      "  inflating: DIV2K_train_HR/0686.png  \r\n",
      "  inflating: DIV2K_train_HR/0053.png  \r\n",
      "  inflating: DIV2K_train_HR/0665.png  \r\n",
      "  inflating: DIV2K_train_HR/0691.png  \r\n",
      "  inflating: DIV2K_train_HR/0167.png  \r\n",
      "  inflating: DIV2K_train_HR/0313.png  \r\n",
      "  inflating: DIV2K_train_HR/0531.png  \r\n",
      "  inflating: DIV2K_train_HR/0569.png  \r\n",
      "  inflating: DIV2K_train_HR/0553.png  \r\n",
      "  inflating: DIV2K_train_HR/0047.png  \r\n",
      "  inflating: DIV2K_train_HR/0096.png  \r\n",
      "  inflating: DIV2K_train_HR/0756.png  \r\n",
      "  inflating: DIV2K_train_HR/0440.png  \r\n",
      "  inflating: DIV2K_train_HR/0199.png  \r\n",
      "  inflating: DIV2K_train_HR/0283.png  \r\n",
      "  inflating: DIV2K_train_HR/0247.png  \r\n",
      "  inflating: DIV2K_train_HR/0024.png  \r\n",
      "  inflating: DIV2K_train_HR/0193.png  \r\n",
      "  inflating: DIV2K_train_HR/0084.png  \r\n",
      "  inflating: DIV2K_train_HR/0102.png  \r\n",
      "  inflating: DIV2K_train_HR/0551.png  \r\n",
      "  inflating: DIV2K_train_HR/0575.png  \r\n",
      "  inflating: DIV2K_train_HR/0477.png  \r\n",
      "  inflating: DIV2K_train_HR/0098.png  \r\n",
      "  inflating: DIV2K_train_HR/0554.png  \r\n",
      "  inflating: DIV2K_train_HR/0189.png  \r\n",
      "  inflating: DIV2K_train_HR/0717.png  \r\n",
      "  inflating: DIV2K_train_HR/0732.png  \r\n",
      "  inflating: DIV2K_train_HR/0702.png  \r\n",
      "  inflating: DIV2K_train_HR/0183.png  \r\n",
      "  inflating: DIV2K_train_HR/0448.png  \r\n",
      "  inflating: DIV2K_train_HR/0455.png  \r\n",
      "  inflating: DIV2K_train_HR/0367.png  \r\n",
      "  inflating: DIV2K_train_HR/0251.png  \r\n",
      "  inflating: DIV2K_train_HR/0744.png  \r\n",
      "  inflating: DIV2K_train_HR/0785.png  \r\n",
      "  inflating: DIV2K_train_HR/0067.png  \r\n",
      "  inflating: DIV2K_train_HR/0163.png  \r\n",
      "  inflating: DIV2K_train_HR/0751.png  \r\n",
      "  inflating: DIV2K_train_HR/0299.png  \r\n",
      "  inflating: DIV2K_train_HR/0129.png  \r\n",
      "  inflating: DIV2K_train_HR/0291.png  \r\n",
      "  inflating: DIV2K_train_HR/0607.png  \r\n",
      "  inflating: DIV2K_train_HR/0242.png  \r\n",
      "  inflating: DIV2K_train_HR/0107.png  \r\n",
      "  inflating: DIV2K_train_HR/0175.png  \r\n",
      "  inflating: DIV2K_train_HR/0753.png  \r\n",
      "  inflating: DIV2K_train_HR/0278.png  \r\n",
      "  inflating: DIV2K_train_HR/0369.png  \r\n",
      "  inflating: DIV2K_train_HR/0571.png  \r\n",
      "  inflating: DIV2K_train_HR/0202.png  \r\n",
      "  inflating: DIV2K_train_HR/0030.png  \r\n",
      "  inflating: DIV2K_train_HR/0799.png  \r\n",
      "  inflating: DIV2K_train_HR/0474.png  \r\n",
      "  inflating: DIV2K_train_HR/0491.png  \r\n",
      "  inflating: DIV2K_train_HR/0638.png  \r\n",
      "  inflating: DIV2K_train_HR/0600.png  \r\n",
      "  inflating: DIV2K_train_HR/0596.png  \r\n",
      "  inflating: DIV2K_train_HR/0059.png  \r\n",
      "  inflating: DIV2K_train_HR/0186.png  \r\n",
      "  inflating: DIV2K_train_HR/0509.png  \r\n",
      "  inflating: DIV2K_train_HR/0529.png  \r\n",
      "  inflating: DIV2K_train_HR/0787.png  \r\n",
      "  inflating: DIV2K_train_HR/0382.png  \r\n",
      "  inflating: DIV2K_train_HR/0777.png  \r\n",
      "  inflating: DIV2K_train_HR/0109.png  \r\n",
      "  inflating: DIV2K_train_HR/0227.png  \r\n",
      "  inflating: DIV2K_train_HR/0388.png  \r\n",
      "  inflating: DIV2K_train_HR/0618.png  \r\n",
      "  inflating: DIV2K_train_HR/0681.png  \r\n",
      "  inflating: DIV2K_train_HR/0205.png  \r\n",
      "  inflating: DIV2K_train_HR/0472.png  \r\n",
      "  inflating: DIV2K_train_HR/0306.png  \r\n",
      "  inflating: DIV2K_train_HR/0361.png  \r\n",
      "  inflating: DIV2K_train_HR/0738.png  \r\n",
      "  inflating: DIV2K_train_HR/0230.png  \r\n",
      "  inflating: DIV2K_train_HR/0081.png  \r\n",
      "  inflating: DIV2K_train_HR/0095.png  \r\n",
      "  inflating: DIV2K_train_HR/0449.png  \r\n",
      "  inflating: DIV2K_train_HR/0626.png  \r\n",
      "  inflating: DIV2K_train_HR/0065.png  \r\n",
      "  inflating: DIV2K_train_HR/0443.png  \r\n",
      "  inflating: DIV2K_train_HR/0275.png  \r\n",
      "  inflating: DIV2K_train_HR/0542.png  \r\n",
      "  inflating: DIV2K_train_HR/0484.png  \r\n",
      "  inflating: DIV2K_train_HR/0359.png  \r\n",
      "  inflating: DIV2K_train_HR/0773.png  \r\n",
      "  inflating: DIV2K_train_HR/0434.png  \r\n",
      "  inflating: DIV2K_train_HR/0544.png  \r\n",
      "  inflating: DIV2K_train_HR/0416.png  \r\n",
      "  inflating: DIV2K_train_HR/0295.png  \r\n",
      "  inflating: DIV2K_train_HR/0538.png  \r\n",
      "  inflating: DIV2K_train_HR/0259.png  \r\n",
      "  inflating: DIV2K_train_HR/0348.png  \r\n",
      "  inflating: DIV2K_train_HR/0588.png  \r\n",
      "  inflating: DIV2K_train_HR/0710.png  \r\n",
      "  inflating: DIV2K_train_HR/0786.png  \r\n",
      "  inflating: DIV2K_train_HR/0185.png  \r\n",
      "  inflating: DIV2K_train_HR/0057.png  \r\n",
      "  inflating: DIV2K_train_HR/0487.png  \r\n",
      "  inflating: DIV2K_train_HR/0683.png  \r\n"
     ]
    }
   ],
   "source": [
    "!unzip ./DIV2K_train_HR.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "209fcf5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T08:36:22.040872Z",
     "iopub.status.busy": "2022-12-04T08:36:22.040191Z",
     "iopub.status.idle": "2022-12-04T08:36:24.688156Z",
     "shell.execute_reply": "2022-12-04T08:36:24.687024Z"
    },
    "papermill": {
     "duration": 2.760241,
     "end_time": "2022-12-04T08:36:24.691015",
     "exception": false,
     "start_time": "2022-12-04T08:36:21.930774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from math import log10\n",
    "\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.utils as utils\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pytorch_ssim\n",
    "from data_utils import TrainDatasetFromFolder, ValDatasetFromFolder, display_transform\n",
    "from loss import GeneratorLoss\n",
    "from model import Generator, Discriminator\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8958f47e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T08:36:24.899189Z",
     "iopub.status.busy": "2022-12-04T08:36:24.898398Z",
     "iopub.status.idle": "2022-12-04T08:36:24.913004Z",
     "shell.execute_reply": "2022-12-04T08:36:24.911704Z"
    },
    "papermill": {
     "duration": 0.11934,
     "end_time": "2022-12-04T08:36:24.915279",
     "exception": false,
     "start_time": "2022-12-04T08:36:24.795939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "CROP_SIZE = 88\n",
    "UPSCALE_FACTOR = 4\n",
    "NUM_EPOCHS = 100\n",
    "train_set = TrainDatasetFromFolder('./DIV2K_train_HR', crop_size=CROP_SIZE, upscale_factor=UPSCALE_FACTOR)\n",
    "val_set = ValDatasetFromFolder('./DIV2K_valid_HR', upscale_factor=UPSCALE_FACTOR)\n",
    "train_loader = DataLoader(dataset=train_set, num_workers=4, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_set, num_workers=4, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fe0bdc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T08:36:25.124395Z",
     "iopub.status.busy": "2022-12-04T08:36:25.124014Z",
     "iopub.status.idle": "2022-12-04T08:36:25.129410Z",
     "shell.execute_reply": "2022-12-04T08:36:25.128349Z"
    },
    "papermill": {
     "duration": 0.114093,
     "end_time": "2022-12-04T08:36:25.131606",
     "exception": false,
     "start_time": "2022-12-04T08:36:25.017513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('/root/.netrc', 'w', encoding='utf-8') as f:\n",
    "    f.write('''machine api.wandb.ai\n",
    "        login user\n",
    "        password a01dcedec2c3c9e23679db3a916d75d2d1da610f\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50df5a63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T08:36:25.566315Z",
     "iopub.status.busy": "2022-12-04T08:36:25.565759Z",
     "iopub.status.idle": "2022-12-04T08:36:27.283997Z",
     "shell.execute_reply": "2022-12-04T08:36:27.282969Z"
    },
    "papermill": {
     "duration": 2.051532,
     "end_time": "2022-12-04T08:36:27.286078",
     "exception": false,
     "start_time": "2022-12-04T08:36:25.234546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbaobao02\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a208208d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T08:36:27.554612Z",
     "iopub.status.busy": "2022-12-04T08:36:27.552870Z",
     "iopub.status.idle": "2022-12-04T08:36:34.713845Z",
     "shell.execute_reply": "2022-12-04T08:36:34.712915Z"
    },
    "papermill": {
     "duration": 7.268102,
     "end_time": "2022-12-04T08:36:34.716356",
     "exception": false,
     "start_time": "2022-12-04T08:36:27.448254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.13.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20221204_083627-zprpgcyf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/baobao02/srgan-my-project/runs/zprpgcyf\" target=\"_blank\">model-srgan-2</a></strong> to <a href=\"https://wandb.ai/baobao02/srgan-my-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/baobao02/srgan-my-project/runs/zprpgcyf?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f2f96932e10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project='srgan-my-project', name='model-srgan-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2c6f452",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T08:36:35.037593Z",
     "iopub.status.busy": "2022-12-04T08:36:35.036954Z",
     "iopub.status.idle": "2022-12-04T08:36:35.335504Z",
     "shell.execute_reply": "2022-12-04T08:36:35.334463Z"
    },
    "papermill": {
     "duration": 0.460981,
     "end_time": "2022-12-04T08:36:35.338115",
     "exception": false,
     "start_time": "2022-12-04T08:36:34.877134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# generator parameters: 734219\n",
      "# discriminator parameters: 5215425\n"
     ]
    }
   ],
   "source": [
    "netG = Generator(UPSCALE_FACTOR)\n",
    "print('# generator parameters:', sum(param.numel() for param in netG.parameters()))\n",
    "netD = Discriminator()\n",
    "print('# discriminator parameters:', sum(param.numel() for param in netD.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1d0f54d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T08:36:35.763971Z",
     "iopub.status.busy": "2022-12-04T08:36:35.763430Z",
     "iopub.status.idle": "2022-12-04T08:37:30.837945Z",
     "shell.execute_reply": "2022-12-04T08:37:30.836943Z"
    },
    "papermill": {
     "duration": 55.248608,
     "end_time": "2022-12-04T08:37:30.840290",
     "exception": false,
     "start_time": "2022-12-04T08:36:35.591682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "765050f864824e97b791e263bed81624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/528M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator_criterion = GeneratorLoss()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    netG.cuda()\n",
    "    netD.cuda()\n",
    "    generator_criterion.cuda()\n",
    "\n",
    "optimizerG = optim.Adam(netG.parameters())\n",
    "optimizerD = optim.Adam(netD.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "057f9952",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T08:37:31.054224Z",
     "iopub.status.busy": "2022-12-04T08:37:31.053851Z",
     "iopub.status.idle": "2022-12-04T08:37:32.074775Z",
     "shell.execute_reply": "2022-12-04T08:37:32.073767Z"
    },
    "papermill": {
     "duration": 1.125952,
     "end_time": "2022-12-04T08:37:32.077027",
     "exception": false,
     "start_time": "2022-12-04T08:37:30.951075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec  4 08:37:31 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   36C    P0    32W / 250W |    733MiB / 16280MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecce0def",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T08:37:32.287464Z",
     "iopub.status.busy": "2022-12-04T08:37:32.287130Z",
     "iopub.status.idle": "2022-12-04T11:17:39.688771Z",
     "shell.execute_reply": "2022-12-04T11:17:39.687579Z"
    },
    "papermill": {
     "duration": 9607.507516,
     "end_time": "2022-12-04T11:17:39.690897",
     "exception": false,
     "start_time": "2022-12-04T08:37:32.183381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "[1/100] Loss_D: 0.8933 Loss_G: 0.0359 D(x): 0.4638 D(G(z)): 0.2765: 100%|██████████| 13/13 [01:02<00:00,  4.79s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 15.1735 dB SSIM: 0.3837: 100%|██████████| 100/100 [00:28<00:00,  3.56it/s]\n",
      "[2/100] Loss_D: 0.4575 Loss_G: 0.0191 D(x): 0.7426 D(G(z)): 0.1133: 100%|██████████| 13/13 [01:01<00:00,  4.75s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 18.5527 dB SSIM: 0.4981: 100%|██████████| 100/100 [00:27<00:00,  3.57it/s]\n",
      "[3/100] Loss_D: 0.7553 Loss_G: 0.0176 D(x): 0.4757 D(G(z)): 0.1839: 100%|██████████| 13/13 [01:01<00:00,  4.73s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 17.8415 dB SSIM: 0.5250: 100%|██████████| 100/100 [00:27<00:00,  3.65it/s]\n",
      "[4/100] Loss_D: 0.7269 Loss_G: 0.0147 D(x): 0.6445 D(G(z)): 0.3190: 100%|██████████| 13/13 [01:01<00:00,  4.70s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 19.5163 dB SSIM: 0.5363: 100%|██████████| 100/100 [00:27<00:00,  3.64it/s]\n",
      "[5/100] Loss_D: 0.9925 Loss_G: 0.0134 D(x): 0.7118 D(G(z)): 0.6902: 100%|██████████| 13/13 [01:00<00:00,  4.64s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 19.3543 dB SSIM: 0.5693: 100%|██████████| 100/100 [00:51<00:00,  1.93it/s]\n",
      "[saving training results]: 100%|██████████| 20/20 [00:22<00:00,  1.10s/it]\n",
      "[6/100] Loss_D: 1.0006 Loss_G: 0.0134 D(x): 0.6969 D(G(z)): 0.6924: 100%|██████████| 13/13 [01:00<00:00,  4.64s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 20.4840 dB SSIM: 0.5701: 100%|██████████| 100/100 [00:27<00:00,  3.57it/s]\n",
      "[7/100] Loss_D: 0.9974 Loss_G: 0.0124 D(x): 0.7110 D(G(z)): 0.7112: 100%|██████████| 13/13 [01:01<00:00,  4.71s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 20.1356 dB SSIM: 0.5866: 100%|██████████| 100/100 [00:28<00:00,  3.56it/s]\n",
      "[8/100] Loss_D: 0.9961 Loss_G: 0.0115 D(x): 0.8092 D(G(z)): 0.8026: 100%|██████████| 13/13 [01:00<00:00,  4.66s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 20.8037 dB SSIM: 0.5949: 100%|██████████| 100/100 [00:27<00:00,  3.58it/s]\n",
      "[9/100] Loss_D: 0.9966 Loss_G: 0.0113 D(x): 0.6649 D(G(z)): 0.6450: 100%|██████████| 13/13 [01:00<00:00,  4.63s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 19.3797 dB SSIM: 0.5904: 100%|██████████| 100/100 [00:27<00:00,  3.59it/s]\n",
      "[10/100] Loss_D: 0.9982 Loss_G: 0.0105 D(x): 0.6319 D(G(z)): 0.6325: 100%|██████████| 13/13 [01:00<00:00,  4.68s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 20.7185 dB SSIM: 0.6071: 100%|██████████| 100/100 [00:50<00:00,  1.98it/s]\n",
      "[saving training results]: 100%|██████████| 20/20 [00:21<00:00,  1.09s/it]\n",
      "[11/100] Loss_D: 0.9940 Loss_G: 0.0091 D(x): 0.6819 D(G(z)): 0.6804: 100%|██████████| 13/13 [00:59<00:00,  4.62s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 21.7056 dB SSIM: 0.6287: 100%|██████████| 100/100 [00:27<00:00,  3.65it/s]\n",
      "[12/100] Loss_D: 1.0033 Loss_G: 0.0091 D(x): 0.7272 D(G(z)): 0.7186: 100%|██████████| 13/13 [00:59<00:00,  4.56s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 21.5302 dB SSIM: 0.6357: 100%|██████████| 100/100 [00:27<00:00,  3.60it/s]\n",
      "[13/100] Loss_D: 0.9993 Loss_G: 0.0096 D(x): 0.6677 D(G(z)): 0.6636: 100%|██████████| 13/13 [01:00<00:00,  4.62s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 20.7767 dB SSIM: 0.6397: 100%|██████████| 100/100 [00:27<00:00,  3.65it/s]\n",
      "[14/100] Loss_D: 1.0077 Loss_G: 0.0107 D(x): 0.7086 D(G(z)): 0.7153: 100%|██████████| 13/13 [00:59<00:00,  4.58s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 21.6836 dB SSIM: 0.6472: 100%|██████████| 100/100 [00:27<00:00,  3.66it/s]\n",
      "[15/100] Loss_D: 0.9991 Loss_G: 0.0080 D(x): 0.7051 D(G(z)): 0.7027: 100%|██████████| 13/13 [00:59<00:00,  4.56s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 22.1743 dB SSIM: 0.6551: 100%|██████████| 100/100 [00:50<00:00,  1.99it/s]\n",
      "[saving training results]: 100%|██████████| 20/20 [00:21<00:00,  1.09s/it]\n",
      "[16/100] Loss_D: 1.0020 Loss_G: 0.0080 D(x): 0.6896 D(G(z)): 0.6911: 100%|██████████| 13/13 [00:59<00:00,  4.55s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 21.3548 dB SSIM: 0.6607: 100%|██████████| 100/100 [00:27<00:00,  3.69it/s]\n",
      "[17/100] Loss_D: 1.0082 Loss_G: 0.0083 D(x): 0.6614 D(G(z)): 0.6691: 100%|██████████| 13/13 [00:58<00:00,  4.52s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 21.5353 dB SSIM: 0.6564: 100%|██████████| 100/100 [00:27<00:00,  3.67it/s]\n",
      "[18/100] Loss_D: 1.0018 Loss_G: 0.0081 D(x): 0.5903 D(G(z)): 0.5714: 100%|██████████| 13/13 [01:00<00:00,  4.62s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 20.8388 dB SSIM: 0.6593: 100%|██████████| 100/100 [00:27<00:00,  3.67it/s]\n",
      "[19/100] Loss_D: 0.9933 Loss_G: 0.0094 D(x): 0.3783 D(G(z)): 0.3651: 100%|██████████| 13/13 [00:59<00:00,  4.59s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 20.4990 dB SSIM: 0.6549: 100%|██████████| 100/100 [00:27<00:00,  3.70it/s]\n",
      "[20/100] Loss_D: 0.9969 Loss_G: 0.0085 D(x): 0.3561 D(G(z)): 0.3548: 100%|██████████| 13/13 [00:59<00:00,  4.61s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 23.0664 dB SSIM: 0.6776: 100%|██████████| 100/100 [00:49<00:00,  2.01it/s]\n",
      "[saving training results]: 100%|██████████| 20/20 [00:22<00:00,  1.10s/it]\n",
      "[21/100] Loss_D: 1.0007 Loss_G: 0.0083 D(x): 0.3749 D(G(z)): 0.3731: 100%|██████████| 13/13 [00:59<00:00,  4.57s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 23.2234 dB SSIM: 0.6864: 100%|██████████| 100/100 [00:26<00:00,  3.71it/s]\n",
      "[22/100] Loss_D: 1.0009 Loss_G: 0.0073 D(x): 0.3813 D(G(z)): 0.3871: 100%|██████████| 13/13 [00:59<00:00,  4.60s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 23.3636 dB SSIM: 0.6879: 100%|██████████| 100/100 [00:27<00:00,  3.66it/s]\n",
      "[23/100] Loss_D: 0.9950 Loss_G: 0.0076 D(x): 0.5037 D(G(z)): 0.5003: 100%|██████████| 13/13 [00:59<00:00,  4.61s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 21.6395 dB SSIM: 0.6858: 100%|██████████| 100/100 [00:27<00:00,  3.66it/s]\n",
      "[24/100] Loss_D: 0.9876 Loss_G: 0.0080 D(x): 0.4201 D(G(z)): 0.4045: 100%|██████████| 13/13 [00:59<00:00,  4.56s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 22.5342 dB SSIM: 0.6960: 100%|██████████| 100/100 [00:27<00:00,  3.62it/s]\n",
      "[25/100] Loss_D: 0.9903 Loss_G: 0.0075 D(x): 0.3739 D(G(z)): 0.3791: 100%|██████████| 13/13 [00:58<00:00,  4.54s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 23.3015 dB SSIM: 0.6898: 100%|██████████| 100/100 [00:50<00:00,  1.97it/s]\n",
      "[saving training results]: 100%|██████████| 20/20 [00:21<00:00,  1.08s/it]\n",
      "[26/100] Loss_D: 0.9933 Loss_G: 0.0075 D(x): 0.5678 D(G(z)): 0.5472: 100%|██████████| 13/13 [00:59<00:00,  4.58s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 22.8062 dB SSIM: 0.6964: 100%|██████████| 100/100 [00:27<00:00,  3.65it/s]\n",
      "[27/100] Loss_D: 0.9870 Loss_G: 0.0078 D(x): 0.3739 D(G(z)): 0.3420: 100%|██████████| 13/13 [00:58<00:00,  4.52s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 21.7338 dB SSIM: 0.6805: 100%|██████████| 100/100 [00:27<00:00,  3.65it/s]\n",
      "[28/100] Loss_D: 0.9992 Loss_G: 0.0084 D(x): 0.2100 D(G(z)): 0.2033: 100%|██████████| 13/13 [00:59<00:00,  4.59s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 22.6366 dB SSIM: 0.6841: 100%|██████████| 100/100 [00:27<00:00,  3.65it/s]\n",
      "[29/100] Loss_D: 1.0025 Loss_G: 0.0088 D(x): 0.2152 D(G(z)): 0.2272: 100%|██████████| 13/13 [00:59<00:00,  4.57s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 21.5543 dB SSIM: 0.6792: 100%|██████████| 100/100 [00:27<00:00,  3.69it/s]\n",
      "[30/100] Loss_D: 1.0002 Loss_G: 0.0073 D(x): 0.4530 D(G(z)): 0.4752: 100%|██████████| 13/13 [00:59<00:00,  4.54s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 21.7697 dB SSIM: 0.6911: 100%|██████████| 100/100 [00:50<00:00,  1.97it/s]\n",
      "[saving training results]: 100%|██████████| 20/20 [00:21<00:00,  1.07s/it]\n",
      "[31/100] Loss_D: 1.0002 Loss_G: 0.0069 D(x): 0.6711 D(G(z)): 0.6796: 100%|██████████| 13/13 [00:59<00:00,  4.56s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 22.8099 dB SSIM: 0.7018: 100%|██████████| 100/100 [00:27<00:00,  3.62it/s]\n",
      "[32/100] Loss_D: 1.0056 Loss_G: 0.0068 D(x): 0.7209 D(G(z)): 0.7253: 100%|██████████| 13/13 [00:59<00:00,  4.60s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 23.5294 dB SSIM: 0.7105: 100%|██████████| 100/100 [00:27<00:00,  3.68it/s]\n",
      "[33/100] Loss_D: 0.9993 Loss_G: 0.0065 D(x): 0.7060 D(G(z)): 0.6950: 100%|██████████| 13/13 [00:59<00:00,  4.60s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 23.2811 dB SSIM: 0.7074: 100%|██████████| 100/100 [00:27<00:00,  3.67it/s]\n",
      "[34/100] Loss_D: 1.0059 Loss_G: 0.0069 D(x): 0.5923 D(G(z)): 0.5900: 100%|██████████| 13/13 [00:59<00:00,  4.55s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 22.7767 dB SSIM: 0.7120: 100%|██████████| 100/100 [00:27<00:00,  3.68it/s]\n",
      "[35/100] Loss_D: 1.0064 Loss_G: 0.0065 D(x): 0.5156 D(G(z)): 0.5132: 100%|██████████| 13/13 [00:59<00:00,  4.55s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 24.0730 dB SSIM: 0.7148: 100%|██████████| 100/100 [00:50<00:00,  1.97it/s]\n",
      "[saving training results]: 100%|██████████| 20/20 [00:21<00:00,  1.08s/it]\n",
      "[36/100] Loss_D: 1.0034 Loss_G: 0.0066 D(x): 0.5486 D(G(z)): 0.5690: 100%|██████████| 13/13 [00:58<00:00,  4.52s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 23.8718 dB SSIM: 0.7126: 100%|██████████| 100/100 [00:27<00:00,  3.61it/s]\n",
      "[37/100] Loss_D: 1.0053 Loss_G: 0.0061 D(x): 0.7385 D(G(z)): 0.7456: 100%|██████████| 13/13 [00:59<00:00,  4.55s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 23.8225 dB SSIM: 0.7185: 100%|██████████| 100/100 [00:27<00:00,  3.64it/s]\n",
      "[38/100] Loss_D: 1.0105 Loss_G: 0.0066 D(x): 0.6760 D(G(z)): 0.6861: 100%|██████████| 13/13 [00:59<00:00,  4.57s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 23.9826 dB SSIM: 0.7162: 100%|██████████| 100/100 [00:27<00:00,  3.68it/s]\n",
      "[39/100] Loss_D: 1.0033 Loss_G: 0.0068 D(x): 0.7106 D(G(z)): 0.7139: 100%|██████████| 13/13 [00:58<00:00,  4.47s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 21.8008 dB SSIM: 0.7014: 100%|██████████| 100/100 [00:27<00:00,  3.65it/s]\n",
      "[40/100] Loss_D: 0.9919 Loss_G: 0.0062 D(x): 0.7811 D(G(z)): 0.7759: 100%|██████████| 13/13 [00:59<00:00,  4.58s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 23.4173 dB SSIM: 0.7014: 100%|██████████| 100/100 [00:50<00:00,  1.97it/s]\n",
      "[saving training results]: 100%|██████████| 20/20 [00:21<00:00,  1.05s/it]\n",
      "[41/100] Loss_D: 0.9908 Loss_G: 0.0067 D(x): 0.7879 D(G(z)): 0.7719: 100%|██████████| 13/13 [01:00<00:00,  4.63s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 23.5849 dB SSIM: 0.7195: 100%|██████████| 100/100 [00:27<00:00,  3.62it/s]\n",
      "[42/100] Loss_D: 1.0025 Loss_G: 0.0060 D(x): 0.6923 D(G(z)): 0.6873: 100%|██████████| 13/13 [01:01<00:00,  4.71s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 23.8298 dB SSIM: 0.7261: 100%|██████████| 100/100 [00:27<00:00,  3.61it/s]\n",
      "[43/100] Loss_D: 0.9986 Loss_G: 0.0062 D(x): 0.6360 D(G(z)): 0.6297: 100%|██████████| 13/13 [01:00<00:00,  4.62s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 22.7673 dB SSIM: 0.7129: 100%|██████████| 100/100 [00:27<00:00,  3.69it/s]\n",
      "[44/100] Loss_D: 1.0039 Loss_G: 0.0069 D(x): 0.6307 D(G(z)): 0.6345: 100%|██████████| 13/13 [00:59<00:00,  4.60s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 23.6850 dB SSIM: 0.7031: 100%|██████████| 100/100 [00:26<00:00,  3.72it/s]\n",
      "[45/100] Loss_D: 1.0028 Loss_G: 0.0063 D(x): 0.6635 D(G(z)): 0.6679: 100%|██████████| 13/13 [00:59<00:00,  4.60s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 23.9424 dB SSIM: 0.7210: 100%|██████████| 100/100 [00:50<00:00,  1.97it/s]\n",
      "[saving training results]: 100%|██████████| 20/20 [00:21<00:00,  1.07s/it]\n",
      "[46/100] Loss_D: 1.0039 Loss_G: 0.0062 D(x): 0.7069 D(G(z)): 0.7119: 100%|██████████| 13/13 [00:59<00:00,  4.57s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 22.8959 dB SSIM: 0.7150: 100%|██████████| 100/100 [00:27<00:00,  3.69it/s]\n",
      "[47/100] Loss_D: 1.0053 Loss_G: 0.0063 D(x): 0.7145 D(G(z)): 0.7192: 100%|██████████| 13/13 [00:59<00:00,  4.57s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 23.3464 dB SSIM: 0.7212: 100%|██████████| 100/100 [00:27<00:00,  3.68it/s]\n",
      "[48/100] Loss_D: 1.0111 Loss_G: 0.0059 D(x): 0.7160 D(G(z)): 0.7241: 100%|██████████| 13/13 [00:58<00:00,  4.54s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 23.1973 dB SSIM: 0.7184: 100%|██████████| 100/100 [00:27<00:00,  3.67it/s]\n",
      "[49/100] Loss_D: 0.9992 Loss_G: 0.0062 D(x): 0.7096 D(G(z)): 0.7073: 100%|██████████| 13/13 [00:58<00:00,  4.50s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 22.4104 dB SSIM: 0.7100: 100%|██████████| 100/100 [00:27<00:00,  3.66it/s]\n",
      "[50/100] Loss_D: 1.0087 Loss_G: 0.0061 D(x): 0.6747 D(G(z)): 0.6788: 100%|██████████| 13/13 [00:59<00:00,  4.55s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 24.3305 dB SSIM: 0.7311: 100%|██████████| 100/100 [00:50<00:00,  1.96it/s]\n",
      "[saving training results]: 100%|██████████| 20/20 [00:21<00:00,  1.07s/it]\n",
      "[51/100] Loss_D: 1.0161 Loss_G: 0.0059 D(x): 0.6521 D(G(z)): 0.6692: 100%|██████████| 13/13 [00:59<00:00,  4.59s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 24.1113 dB SSIM: 0.7288: 100%|██████████| 100/100 [00:27<00:00,  3.70it/s]\n",
      "[52/100] Loss_D: 1.0126 Loss_G: 0.0063 D(x): 0.7023 D(G(z)): 0.7181: 100%|██████████| 13/13 [00:59<00:00,  4.58s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 23.8071 dB SSIM: 0.7234: 100%|██████████| 100/100 [00:27<00:00,  3.67it/s]\n",
      "[53/100] Loss_D: 1.0106 Loss_G: 0.0058 D(x): 0.7495 D(G(z)): 0.7666: 100%|██████████| 13/13 [00:59<00:00,  4.59s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 23.7001 dB SSIM: 0.7262: 100%|██████████| 100/100 [00:26<00:00,  3.72it/s]\n",
      "[54/100] Loss_D: 0.9944 Loss_G: 0.0059 D(x): 0.7452 D(G(z)): 0.7294: 100%|██████████| 13/13 [00:58<00:00,  4.53s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 24.0263 dB SSIM: 0.7322: 100%|██████████| 100/100 [00:27<00:00,  3.68it/s]\n",
      "[55/100] Loss_D: 1.0003 Loss_G: 0.0064 D(x): 0.7058 D(G(z)): 0.7073: 100%|██████████| 13/13 [00:59<00:00,  4.54s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 23.6374 dB SSIM: 0.7271: 100%|██████████| 100/100 [00:50<00:00,  1.99it/s]\n",
      "[saving training results]: 100%|██████████| 20/20 [00:21<00:00,  1.07s/it]\n",
      "[56/100] Loss_D: 0.9963 Loss_G: 0.0058 D(x): 0.6437 D(G(z)): 0.6306: 100%|██████████| 13/13 [00:59<00:00,  4.61s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 23.9250 dB SSIM: 0.7171: 100%|██████████| 100/100 [00:27<00:00,  3.64it/s]\n",
      "[57/100] Loss_D: 0.9994 Loss_G: 0.0056 D(x): 0.6711 D(G(z)): 0.6730: 100%|██████████| 13/13 [00:59<00:00,  4.61s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 24.3025 dB SSIM: 0.7255: 100%|██████████| 100/100 [00:27<00:00,  3.64it/s]\n",
      "[58/100] Loss_D: 1.0038 Loss_G: 0.0054 D(x): 0.7167 D(G(z)): 0.7139: 100%|██████████| 13/13 [00:59<00:00,  4.60s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 24.4669 dB SSIM: 0.7322: 100%|██████████| 100/100 [00:27<00:00,  3.65it/s]\n",
      "[59/100] Loss_D: 0.9938 Loss_G: 0.0057 D(x): 0.7460 D(G(z)): 0.7394: 100%|██████████| 13/13 [00:59<00:00,  4.59s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 22.8689 dB SSIM: 0.7252: 100%|██████████| 100/100 [00:27<00:00,  3.62it/s]\n",
      "[60/100] Loss_D: 0.9993 Loss_G: 0.0067 D(x): 0.7565 D(G(z)): 0.7450: 100%|██████████| 13/13 [00:59<00:00,  4.57s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 23.7171 dB SSIM: 0.7326: 100%|██████████| 100/100 [00:50<00:00,  1.98it/s]\n",
      "[saving training results]: 100%|██████████| 20/20 [00:21<00:00,  1.06s/it]\n",
      "[61/100] Loss_D: 1.0099 Loss_G: 0.0053 D(x): 0.7704 D(G(z)): 0.7811: 100%|██████████| 13/13 [00:59<00:00,  4.61s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 24.3001 dB SSIM: 0.7323: 100%|██████████| 100/100 [00:27<00:00,  3.67it/s]\n",
      "[62/100] Loss_D: 1.0134 Loss_G: 0.0063 D(x): 0.7748 D(G(z)): 0.7850: 100%|██████████| 13/13 [00:59<00:00,  4.56s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 23.9178 dB SSIM: 0.7270: 100%|██████████| 100/100 [00:27<00:00,  3.67it/s]\n",
      "[63/100] Loss_D: 1.0042 Loss_G: 0.0053 D(x): 0.7674 D(G(z)): 0.7648: 100%|██████████| 13/13 [00:58<00:00,  4.54s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 24.1725 dB SSIM: 0.7288: 100%|██████████| 100/100 [00:27<00:00,  3.70it/s]\n",
      "[64/100] Loss_D: 1.0046 Loss_G: 0.0057 D(x): 0.7532 D(G(z)): 0.7542: 100%|██████████| 13/13 [00:59<00:00,  4.60s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 23.9711 dB SSIM: 0.7230: 100%|██████████| 100/100 [00:27<00:00,  3.68it/s]\n",
      "[65/100] Loss_D: 0.9970 Loss_G: 0.0054 D(x): 0.7542 D(G(z)): 0.7502: 100%|██████████| 13/13 [00:59<00:00,  4.58s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 24.3499 dB SSIM: 0.7330: 100%|██████████| 100/100 [00:49<00:00,  2.00it/s]\n",
      "[saving training results]: 100%|██████████| 20/20 [00:21<00:00,  1.08s/it]\n",
      "[66/100] Loss_D: 0.9984 Loss_G: 0.0058 D(x): 0.7309 D(G(z)): 0.7270: 100%|██████████| 13/13 [01:00<00:00,  4.62s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 24.3643 dB SSIM: 0.7303: 100%|██████████| 100/100 [00:26<00:00,  3.71it/s]\n",
      "[67/100] Loss_D: 1.0054 Loss_G: 0.0056 D(x): 0.6956 D(G(z)): 0.6977: 100%|██████████| 13/13 [00:59<00:00,  4.59s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 24.3683 dB SSIM: 0.7303: 100%|██████████| 100/100 [00:27<00:00,  3.70it/s]\n",
      "[68/100] Loss_D: 0.9982 Loss_G: 0.0055 D(x): 0.6804 D(G(z)): 0.6662: 100%|██████████| 13/13 [00:58<00:00,  4.54s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 24.1739 dB SSIM: 0.7357: 100%|██████████| 100/100 [00:27<00:00,  3.62it/s]\n",
      "[69/100] Loss_D: 1.0050 Loss_G: 0.0056 D(x): 0.6221 D(G(z)): 0.6269: 100%|██████████| 13/13 [00:59<00:00,  4.57s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 23.3853 dB SSIM: 0.7141: 100%|██████████| 100/100 [00:27<00:00,  3.68it/s]\n",
      "[70/100] Loss_D: 1.0051 Loss_G: 0.0059 D(x): 0.6397 D(G(z)): 0.6427: 100%|██████████| 13/13 [00:59<00:00,  4.58s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 24.3094 dB SSIM: 0.7355: 100%|██████████| 100/100 [00:49<00:00,  2.01it/s]\n",
      "[saving training results]: 100%|██████████| 20/20 [00:21<00:00,  1.09s/it]\n",
      "[71/100] Loss_D: 0.9970 Loss_G: 0.0062 D(x): 0.6144 D(G(z)): 0.6077: 100%|██████████| 13/13 [00:59<00:00,  4.61s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 23.6825 dB SSIM: 0.7295: 100%|██████████| 100/100 [00:27<00:00,  3.67it/s]\n",
      "[72/100] Loss_D: 0.9950 Loss_G: 0.0055 D(x): 0.5828 D(G(z)): 0.5793: 100%|██████████| 13/13 [00:59<00:00,  4.56s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 24.0137 dB SSIM: 0.7374: 100%|██████████| 100/100 [00:27<00:00,  3.70it/s]\n",
      "[73/100] Loss_D: 0.9958 Loss_G: 0.0059 D(x): 0.6235 D(G(z)): 0.6199: 100%|██████████| 13/13 [00:59<00:00,  4.57s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 23.8086 dB SSIM: 0.7263: 100%|██████████| 100/100 [00:27<00:00,  3.67it/s]\n",
      "[74/100] Loss_D: 1.0007 Loss_G: 0.0057 D(x): 0.6493 D(G(z)): 0.6541: 100%|██████████| 13/13 [00:59<00:00,  4.61s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 23.8405 dB SSIM: 0.7272: 100%|██████████| 100/100 [00:27<00:00,  3.69it/s]\n",
      "[75/100] Loss_D: 1.0036 Loss_G: 0.0056 D(x): 0.6779 D(G(z)): 0.6799: 100%|██████████| 13/13 [00:59<00:00,  4.60s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 23.2799 dB SSIM: 0.7183: 100%|██████████| 100/100 [00:49<00:00,  2.01it/s]\n",
      "[saving training results]: 100%|██████████| 20/20 [00:21<00:00,  1.09s/it]\n",
      "[76/100] Loss_D: 1.0016 Loss_G: 0.0057 D(x): 0.6601 D(G(z)): 0.6609: 100%|██████████| 13/13 [00:59<00:00,  4.56s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 23.9144 dB SSIM: 0.7325: 100%|██████████| 100/100 [00:27<00:00,  3.68it/s]\n",
      "[77/100] Loss_D: 1.0038 Loss_G: 0.0061 D(x): 0.6805 D(G(z)): 0.6853: 100%|██████████| 13/13 [00:59<00:00,  4.56s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 23.4420 dB SSIM: 0.7311: 100%|██████████| 100/100 [00:26<00:00,  3.74it/s]\n",
      "[78/100] Loss_D: 1.0034 Loss_G: 0.0054 D(x): 0.7110 D(G(z)): 0.7158: 100%|██████████| 13/13 [00:59<00:00,  4.57s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 24.2029 dB SSIM: 0.7348: 100%|██████████| 100/100 [00:27<00:00,  3.67it/s]\n",
      "[79/100] Loss_D: 1.0048 Loss_G: 0.0053 D(x): 0.7051 D(G(z)): 0.7086: 100%|██████████| 13/13 [00:59<00:00,  4.56s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 24.4292 dB SSIM: 0.7270: 100%|██████████| 100/100 [00:27<00:00,  3.69it/s]\n",
      "[80/100] Loss_D: 1.0007 Loss_G: 0.0052 D(x): 0.6957 D(G(z)): 0.6959: 100%|██████████| 13/13 [00:59<00:00,  4.56s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 23.8231 dB SSIM: 0.7358: 100%|██████████| 100/100 [00:50<00:00,  2.00it/s]\n",
      "[saving training results]: 100%|██████████| 20/20 [00:22<00:00,  1.11s/it]\n",
      "[81/100] Loss_D: 0.9965 Loss_G: 0.0053 D(x): 0.7040 D(G(z)): 0.7003: 100%|██████████| 13/13 [00:59<00:00,  4.57s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 23.9775 dB SSIM: 0.7238: 100%|██████████| 100/100 [00:27<00:00,  3.68it/s]\n",
      "[82/100] Loss_D: 1.0014 Loss_G: 0.0055 D(x): 0.6875 D(G(z)): 0.6878: 100%|██████████| 13/13 [00:58<00:00,  4.50s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 24.5185 dB SSIM: 0.7402: 100%|██████████| 100/100 [00:27<00:00,  3.62it/s]\n",
      "[83/100] Loss_D: 0.9963 Loss_G: 0.0050 D(x): 0.7007 D(G(z)): 0.6943: 100%|██████████| 13/13 [00:59<00:00,  4.60s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 24.6219 dB SSIM: 0.7372: 100%|██████████| 100/100 [00:27<00:00,  3.69it/s]\n",
      "[84/100] Loss_D: 1.0050 Loss_G: 0.0051 D(x): 0.6568 D(G(z)): 0.6561: 100%|██████████| 13/13 [00:59<00:00,  4.59s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 24.2785 dB SSIM: 0.7392: 100%|██████████| 100/100 [00:27<00:00,  3.68it/s]\n",
      "[85/100] Loss_D: 1.0013 Loss_G: 0.0055 D(x): 0.6304 D(G(z)): 0.6309: 100%|██████████| 13/13 [00:59<00:00,  4.61s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 24.1500 dB SSIM: 0.7350: 100%|██████████| 100/100 [00:50<00:00,  2.00it/s]\n",
      "[saving training results]: 100%|██████████| 20/20 [00:21<00:00,  1.10s/it]\n",
      "[86/100] Loss_D: 1.0012 Loss_G: 0.0054 D(x): 0.6426 D(G(z)): 0.6454: 100%|██████████| 13/13 [00:59<00:00,  4.56s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 23.5356 dB SSIM: 0.7355: 100%|██████████| 100/100 [00:27<00:00,  3.65it/s]\n",
      "[87/100] Loss_D: 1.0032 Loss_G: 0.0053 D(x): 0.6682 D(G(z)): 0.6714: 100%|██████████| 13/13 [00:58<00:00,  4.53s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 24.4620 dB SSIM: 0.7422: 100%|██████████| 100/100 [00:27<00:00,  3.66it/s]\n",
      "[88/100] Loss_D: 1.0003 Loss_G: 0.0058 D(x): 0.6638 D(G(z)): 0.6630: 100%|██████████| 13/13 [01:00<00:00,  4.62s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 24.4223 dB SSIM: 0.7396: 100%|██████████| 100/100 [00:27<00:00,  3.68it/s]\n",
      "[89/100] Loss_D: 0.9989 Loss_G: 0.0051 D(x): 0.6645 D(G(z)): 0.6649: 100%|██████████| 13/13 [00:59<00:00,  4.58s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 24.3682 dB SSIM: 0.7321: 100%|██████████| 100/100 [00:27<00:00,  3.65it/s]\n",
      "[90/100] Loss_D: 0.9996 Loss_G: 0.0051 D(x): 0.6982 D(G(z)): 0.6989: 100%|██████████| 13/13 [00:59<00:00,  4.56s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 24.2594 dB SSIM: 0.7423: 100%|██████████| 100/100 [00:50<00:00,  2.00it/s]\n",
      "[saving training results]: 100%|██████████| 20/20 [00:22<00:00,  1.10s/it]\n",
      "[91/100] Loss_D: 1.0016 Loss_G: 0.0053 D(x): 0.7274 D(G(z)): 0.7296: 100%|██████████| 13/13 [00:59<00:00,  4.55s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 24.2379 dB SSIM: 0.7403: 100%|██████████| 100/100 [00:27<00:00,  3.67it/s]\n",
      "[92/100] Loss_D: 1.0061 Loss_G: 0.0054 D(x): 0.7654 D(G(z)): 0.7677: 100%|██████████| 13/13 [00:58<00:00,  4.51s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 24.3074 dB SSIM: 0.7428: 100%|██████████| 100/100 [00:27<00:00,  3.62it/s]\n",
      "[93/100] Loss_D: 1.0044 Loss_G: 0.0051 D(x): 0.7184 D(G(z)): 0.7235: 100%|██████████| 13/13 [00:59<00:00,  4.58s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 24.3818 dB SSIM: 0.7451: 100%|██████████| 100/100 [00:27<00:00,  3.70it/s]\n",
      "[94/100] Loss_D: 1.0020 Loss_G: 0.0051 D(x): 0.7059 D(G(z)): 0.7027: 100%|██████████| 13/13 [01:00<00:00,  4.63s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 24.6025 dB SSIM: 0.7464: 100%|██████████| 100/100 [00:27<00:00,  3.64it/s]\n",
      "[95/100] Loss_D: 0.9997 Loss_G: 0.0053 D(x): 0.7003 D(G(z)): 0.7033: 100%|██████████| 13/13 [01:01<00:00,  4.77s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 24.2870 dB SSIM: 0.7424: 100%|██████████| 100/100 [00:50<00:00,  1.98it/s]\n",
      "[saving training results]: 100%|██████████| 20/20 [00:22<00:00,  1.11s/it]\n",
      "[96/100] Loss_D: 0.9933 Loss_G: 0.0052 D(x): 0.7405 D(G(z)): 0.7268: 100%|██████████| 13/13 [00:59<00:00,  4.59s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 24.5716 dB SSIM: 0.7421: 100%|██████████| 100/100 [00:27<00:00,  3.67it/s]\n",
      "[97/100] Loss_D: 1.0025 Loss_G: 0.0053 D(x): 0.7017 D(G(z)): 0.7068: 100%|██████████| 13/13 [00:59<00:00,  4.59s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 24.5004 dB SSIM: 0.7444: 100%|██████████| 100/100 [00:27<00:00,  3.67it/s]\n",
      "[98/100] Loss_D: 1.0078 Loss_G: 0.0053 D(x): 0.6523 D(G(z)): 0.6559: 100%|██████████| 13/13 [01:00<00:00,  4.62s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 24.5590 dB SSIM: 0.7387: 100%|██████████| 100/100 [00:27<00:00,  3.66it/s]\n",
      "[99/100] Loss_D: 1.0093 Loss_G: 0.0052 D(x): 0.6684 D(G(z)): 0.6859: 100%|██████████| 13/13 [01:00<00:00,  4.63s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 24.5252 dB SSIM: 0.7385: 100%|██████████| 100/100 [00:27<00:00,  3.68it/s]\n",
      "[100/100] Loss_D: 1.0091 Loss_G: 0.0049 D(x): 0.6618 D(G(z)): 0.6656: 100%|██████████| 13/13 [01:00<00:00,  4.63s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "[converting LR images to SR images] PSNR: 24.1354 dB SSIM: 0.7426: 100%|██████████| 100/100 [00:50<00:00,  1.98it/s]\n",
      "[saving training results]: 100%|██████████| 20/20 [00:21<00:00,  1.09s/it]\n"
     ]
    }
   ],
   "source": [
    "results = {'d_loss': [], 'g_loss': [], 'd_score': [], 'g_score': [], 'psnr': [], 'ssim': []}\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    train_bar = tqdm(train_loader)\n",
    "    running_results = {'batch_sizes': 0, 'd_loss': 0, 'g_loss': 0, 'd_score': 0, 'g_score': 0}\n",
    "\n",
    "    netG.train()\n",
    "    netD.train()\n",
    "    for data, target in train_bar:\n",
    "        g_update_first = True\n",
    "        batch_size = data.size(0)\n",
    "        running_results['batch_sizes'] += batch_size\n",
    "\n",
    "        ############################\n",
    "        # (1) Update D network: maximize D(x)-1-D(G(z))\n",
    "        ###########################\n",
    "        real_img = Variable(target)\n",
    "        if torch.cuda.is_available():\n",
    "            real_img = real_img.cuda()\n",
    "        z = Variable(data)\n",
    "        if torch.cuda.is_available():\n",
    "            z = z.cuda()\n",
    "        fake_img = netG(z)\n",
    "\n",
    "        netD.zero_grad()\n",
    "        real_out = netD(real_img).mean()\n",
    "        fake_out = netD(fake_img).mean()\n",
    "        d_loss = 1 - real_out + fake_out\n",
    "        d_loss.backward(retain_graph=True)\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: minimize 1-D(G(z)) + Perception Loss + Image Loss + TV Loss\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        ## The two lines below are added to prevent runetime error in Google Colab ##\n",
    "        fake_img = netG(z)\n",
    "        fake_out = netD(fake_img).mean()\n",
    "        ##\n",
    "        g_loss = generator_criterion(fake_out, fake_img, real_img)\n",
    "        g_loss.backward()\n",
    "        \n",
    "        fake_img = netG(z)\n",
    "        fake_out = netD(fake_img).mean()\n",
    "        \n",
    "        \n",
    "        optimizerG.step()\n",
    "\n",
    "        # loss for current batch before optimization \n",
    "        running_results['g_loss'] += g_loss.item() * batch_size\n",
    "        running_results['d_loss'] += d_loss.item() * batch_size\n",
    "        running_results['d_score'] += real_out.item() * batch_size\n",
    "        running_results['g_score'] += fake_out.item() * batch_size\n",
    "\n",
    "        train_bar.set_description(desc='[%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f' % (\n",
    "            epoch, NUM_EPOCHS, running_results['d_loss'] / running_results['batch_sizes'],\n",
    "            running_results['g_loss'] / running_results['batch_sizes'],\n",
    "            running_results['d_score'] / running_results['batch_sizes'],\n",
    "            running_results['g_score'] / running_results['batch_sizes']))\n",
    "\n",
    "    netG.eval()\n",
    "    out_path = 'training_results/SRF_' + str(UPSCALE_FACTOR) + '/'\n",
    "    if not os.path.exists(out_path):\n",
    "        os.makedirs(out_path)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(val_loader)\n",
    "        valing_results = {'mse': 0, 'ssims': 0, 'psnr': 0, 'ssim': 0, 'batch_sizes': 0}\n",
    "        val_images = []\n",
    "        for val_lr, val_hr_restore, val_hr in val_bar:\n",
    "            batch_size = val_lr.size(0)\n",
    "            valing_results['batch_sizes'] += batch_size\n",
    "            lr = val_lr\n",
    "            hr = val_hr\n",
    "            if torch.cuda.is_available():\n",
    "                lr = lr.cuda()\n",
    "                hr = hr.cuda()\n",
    "            sr = netG(lr)\n",
    "    \n",
    "            batch_mse = ((sr - hr) ** 2).data.mean()\n",
    "            valing_results['mse'] += batch_mse * batch_size\n",
    "            batch_ssim = pytorch_ssim.ssim(sr, hr).item()\n",
    "            valing_results['ssims'] += batch_ssim * batch_size\n",
    "            valing_results['psnr'] = 10 * log10((hr.max()**2) / (valing_results['mse'] / valing_results['batch_sizes']))\n",
    "            valing_results['ssim'] = valing_results['ssims'] / valing_results['batch_sizes']\n",
    "            val_bar.set_description(\n",
    "                desc='[converting LR images to SR images] PSNR: %.4f dB SSIM: %.4f' % (\n",
    "                    valing_results['psnr'], valing_results['ssim']))\n",
    "            if epoch % 5 == 0 and epoch != 0:\n",
    "                val_images.extend(\n",
    "                    [display_transform()(val_hr_restore.squeeze(0)), display_transform()(hr.data.cpu().squeeze(0)),\n",
    "                      display_transform()(sr.data.cpu().squeeze(0))])\n",
    "        if epoch % 5 == 0 and epoch != 0:     \n",
    "            val_images = torch.stack(val_images)\n",
    "            val_images = torch.chunk(val_images, val_images.size(0) // 15)\n",
    "            val_save_bar = tqdm(val_images, desc='[saving training results]')\n",
    "            index = 1\n",
    "            for image in val_save_bar:\n",
    "                image = utils.make_grid(image, nrow=3, padding=5)\n",
    "                utils.save_image(image, out_path + 'epoch_%d_index_%d.png' % (epoch, index), padding=5)\n",
    "                index += 1\n",
    "            # save model parameters\n",
    "            torch.save(netG.state_dict(), 'epochs/netG_epoch_%d_%d.pth' % (UPSCALE_FACTOR, epoch))\n",
    "            torch.save(netD.state_dict(), 'epochs/netD_epoch_%d_%d.pth' % (UPSCALE_FACTOR, epoch))\n",
    "    # save loss\\scores\\psnr\\ssim\n",
    "    results['d_loss'].append(running_results['d_loss'] / running_results['batch_sizes'])\n",
    "    results['g_loss'].append(running_results['g_loss'] / running_results['batch_sizes'])\n",
    "    results['d_score'].append(running_results['d_score'] / running_results['batch_sizes'])\n",
    "    results['g_score'].append(running_results['g_score'] / running_results['batch_sizes'])\n",
    "    results['psnr'].append(valing_results['psnr'])\n",
    "    results['ssim'].append(valing_results['ssim'])\n",
    "    wandb.log({'Loss_D': results['d_loss'], 'Loss_G': results['g_loss'], 'Score_D': results['d_score'],\n",
    "                      'Score_G': results['g_score'], 'PSNR': results['psnr'], 'SSIM': results['ssim']})\n",
    "        \n",
    "    if epoch %10 == 0  and epoch != 0:\n",
    "        out_path = 'statistics/'\n",
    "        data_frame = pd.DataFrame(\n",
    "            data={'Loss_D': results['d_loss'], 'Loss_G': results['g_loss'], 'Score_D': results['d_score'],\n",
    "                  'Score_G': results['g_score'], 'PSNR': results['psnr'], 'SSIM': results['ssim']},\n",
    "            \n",
    "            index=range(1, epoch + 1))\n",
    "        data_frame.to_csv(out_path + 'srf_' + str(UPSCALE_FACTOR) + '_train_results.csv', index_label='Epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c9a870",
   "metadata": {
    "papermill": {
     "duration": 1.390471,
     "end_time": "2022-12-04T11:17:42.700185",
     "exception": false,
     "start_time": "2022-12-04T11:17:41.309714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10060.700358,
   "end_time": "2022-12-04T11:17:47.025805",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-04T08:30:06.325447",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0505d9f541cb480a889c7b9f91ab910d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "LabelModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "LabelView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a9153a7965124a3e941611a1311e231c",
       "placeholder": "​",
       "style": "IPY_MODEL_d962d99e56be4608b12e387879b0d9b1",
       "value": ""
      }
     },
     "0c969fcc041a4bd2a71ccd843a5af359": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1d345ef47a0d45079a361827814d5b53": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "243c9e7a47c44cebaf91ca4c6bada83e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2bc91c4c3bdf4d50891e1e563ba3e154": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3f23f47c828d4abfb86026b6c9fd0005": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "571793c3c0364768a41a0f4a98fa039d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0505d9f541cb480a889c7b9f91ab910d",
        "IPY_MODEL_d6454421599343cf98f5f4b0de28902b"
       ],
       "layout": "IPY_MODEL_1d345ef47a0d45079a361827814d5b53"
      }
     },
     "627973215cdf4b82a811f755d3e09d45": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6e4c3061c2104467bcc287adbbd66c21": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_add7320a7241463581b09bc2fd5a2b7c",
       "placeholder": "​",
       "style": "IPY_MODEL_fa4e35155ca544bb920c9f9a345752d3",
       "value": "100%"
      }
     },
     "6f6591485b824d74ae9009204e98d3ab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_840de09d2c924aefb9d272b1b57d9937",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_627973215cdf4b82a811f755d3e09d45",
       "value": 0.0
      }
     },
     "74c004e02fb24cd9804eb72eb9c4d253": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9b3ca0a14f38408b9d49327451204d23",
        "IPY_MODEL_6f6591485b824d74ae9009204e98d3ab"
       ],
       "layout": "IPY_MODEL_df9fb99bc1a94e90be58f1ac29cf7140"
      }
     },
     "765050f864824e97b791e263bed81624": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6e4c3061c2104467bcc287adbbd66c21",
        "IPY_MODEL_bb2bef502f4e43cab85bd4de9422d71d",
        "IPY_MODEL_98540a4be0a645c3832afbac4b4700ef"
       ],
       "layout": "IPY_MODEL_b5d9e28aea63479c9483923fb0b9364c"
      }
     },
     "840de09d2c924aefb9d272b1b57d9937": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8dfa2aab1513402983829a24e01ce97c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "98540a4be0a645c3832afbac4b4700ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a37b6ba21e6645f39efae2cd4c2ab486",
       "placeholder": "​",
       "style": "IPY_MODEL_2bc91c4c3bdf4d50891e1e563ba3e154",
       "value": " 528M/528M [00:48&lt;00:00, 12.4MB/s]"
      }
     },
     "9b3ca0a14f38408b9d49327451204d23": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "LabelModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "LabelView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8dfa2aab1513402983829a24e01ce97c",
       "placeholder": "​",
       "style": "IPY_MODEL_a1a8e557c3004565be592f5ce0ce11be",
       "value": ""
      }
     },
     "a1a8e557c3004565be592f5ce0ce11be": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a37b6ba21e6645f39efae2cd4c2ab486": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a9153a7965124a3e941611a1311e231c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "add7320a7241463581b09bc2fd5a2b7c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b5d9e28aea63479c9483923fb0b9364c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bb2bef502f4e43cab85bd4de9422d71d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bd4c3ce65a034434899e63d8d37c0ef4",
       "max": 553433881.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0c969fcc041a4bd2a71ccd843a5af359",
       "value": 553433881.0
      }
     },
     "bd4c3ce65a034434899e63d8d37c0ef4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d6454421599343cf98f5f4b0de28902b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3f23f47c828d4abfb86026b6c9fd0005",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_243c9e7a47c44cebaf91ca4c6bada83e",
       "value": 0.0
      }
     },
     "d962d99e56be4608b12e387879b0d9b1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "df9fb99bc1a94e90be58f1ac29cf7140": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fa4e35155ca544bb920c9f9a345752d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
