{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from __future__ import print_function\n%matplotlib inline\nimport argparse\nimport os\nimport random\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nimport torch.utils.data\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nimport torchvision.utils as vutils\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nfrom IPython.display import HTML\n\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-17T15:08:37.461700Z","iopub.execute_input":"2022-12-17T15:08:37.462032Z","iopub.status.idle":"2022-12-17T15:08:39.938073Z","shell.execute_reply.started":"2022-12-17T15:08:37.461952Z","shell.execute_reply":"2022-12-17T15:08:39.936881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_modelG = \"../input/dcgan-model-2/g_checkpoints_epoch-30.pt\"\npath_modelD = \"../input/dcgan-model-2/d_checkpoints_epoch-30.pt\"\n\nroot_data = \"../input/celeba-dataset/\"","metadata":{"execution":{"iopub.status.busy":"2022-12-17T15:08:39.943996Z","iopub.execute_input":"2022-12-17T15:08:39.944571Z","iopub.status.idle":"2022-12-17T15:08:39.954459Z","shell.execute_reply.started":"2022-12-17T15:08:39.944530Z","shell.execute_reply":"2022-12-17T15:08:39.953541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"manualSeed = 999\nprint(\"Random Seed: \", manualSeed)\nrandom.seed(manualSeed)\ntorch.manual_seed(manualSeed)\n\nbatch_size = 128\nimage_size = 64\nnc = 3\nnoise_dim = 100\nnum_epochs = 0\nlr = 0.0002\nbeta1 = 0.5\niter_check = 2000\nprint_check = 100\ndemo_batch_size = 5\n\ndevice = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-12-17T15:08:39.958919Z","iopub.execute_input":"2022-12-17T15:08:39.961566Z","iopub.status.idle":"2022-12-17T15:08:40.035049Z","shell.execute_reply.started":"2022-12-17T15:08:39.961528Z","shell.execute_reply":"2022-12-17T15:08:40.034098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nc = 3\nnz = 100\nngf = 64\nndf = 64\n\nngpu = 1","metadata":{"execution":{"iopub.status.busy":"2022-12-17T15:08:40.040178Z","iopub.execute_input":"2022-12-17T15:08:40.040796Z","iopub.status.idle":"2022-12-17T15:08:40.048722Z","shell.execute_reply.started":"2022-12-17T15:08:40.040758Z","shell.execute_reply":"2022-12-17T15:08:40.047681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# custom weights initialization called on netG and netD\ndef weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        nn.init.normal_(m.weight.data, 0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        nn.init.normal_(m.weight.data, 1.0, 0.02)\n        nn.init.constant_(m.bias.data, 0)","metadata":{"execution":{"iopub.status.busy":"2022-12-17T15:08:40.053043Z","iopub.execute_input":"2022-12-17T15:08:40.054193Z","iopub.status.idle":"2022-12-17T15:08:40.065248Z","shell.execute_reply.started":"2022-12-17T15:08:40.054156Z","shell.execute_reply":"2022-12-17T15:08:40.064101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generator Code\nclass Generator(nn.Module):\n    def __init__(self, ngpu):\n        super(Generator, self).__init__()\n        self.ngpu = ngpu\n        self.main = nn.Sequential(\n            # input is Z, going into a convolution\n            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),# (ngf*8) x 4 x 4\n            nn.BatchNorm2d(ngf * 8),\n            nn.ReLU(True),\n            \n            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False), # (ngf*4) x 8 x 8\n            nn.BatchNorm2d(ngf * 4), \n            nn.ReLU(True),\n            \n            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),# (ngf*2) x 16 x 16\n            nn.BatchNorm2d(ngf * 2),\n            nn.ReLU(True),\n            \n            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),#ngf) x 32 x 32\n            nn.BatchNorm2d(ngf),\n            nn.ReLU(True),\n            \n            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False), #(nc) x 64 x 64\n            nn.Tanh()\n        )\n\n    def forward(self, input):\n        return self.main(input)\n    \n# Create the generator\nnetG = Generator(ngpu).to(device)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nif (device.type == 'cuda') and (ngpu > 1):\n    netG = nn.DataParallel(netG, list(range(ngpu)))\nnetG.apply(weights_init)\nprint(netG)\n\n# ==================\n# Discriminator Code\n# ==================\nclass Discriminator(nn.Module):\n    def __init__(self, ngpu):\n        super(Discriminator, self).__init__()\n        self.ngpu = ngpu\n        self.main = nn.Sequential(\n            \n            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False), # input is (nc) x 64 x 64\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False), #(ndf) x 32 x 32\n            nn.BatchNorm2d(ndf * 2),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),#(ndf*2) x 16 x 16\n            nn.BatchNorm2d(ndf * 4),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),#(ndf*4) x 8 x 8\n            nn.BatchNorm2d(ndf * 8),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),# state size. (ndf*8) x 4 x 4\n            nn.Sigmoid()\n        )\n\n    def forward(self, input):\n        return self.main(input)\n\n# Create the Discriminator\nnetD = Discriminator(ngpu).to(device)\n# Handle multi-gpu if desired\nif (device.type == 'cuda') and (ngpu > 1):\n    netD = nn.DataParallel(netD, list(range(ngpu)))\n# Apply the weights_init function to randomly initialize all weights\n#  to mean=0, stdev=0.2.\nnetD.apply(weights_init)\nprint(netD)","metadata":{"execution":{"iopub.status.busy":"2022-12-17T15:08:40.069286Z","iopub.execute_input":"2022-12-17T15:08:40.070205Z","iopub.status.idle":"2022-12-17T15:08:43.393442Z","shell.execute_reply.started":"2022-12-17T15:08:40.070169Z","shell.execute_reply":"2022-12-17T15:08:43.391560Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pretrainedG = torch.load(path_modelG)\npretrainedD = torch.load(path_modelD)\n\nGen_eval = Generator(ngpu).to(device)\nDis_eval = Discriminator(ngpu).to(device)\n\nGen_eval.load_state_dict(pretrainedG[\"model_state_dict\"])\nDis_eval.load_state_dict(pretrainedD[\"model_state_dict\"])\n\nGen_eval.eval()\nDis_eval.eval()\n\nfor p in Gen_eval.parameters():\n    p.requires_grad=False\n    \nfor p in Dis_eval.parameters():\n    p.requires_grad=False","metadata":{"execution":{"iopub.status.busy":"2022-12-17T15:08:43.395091Z","iopub.execute_input":"2022-12-17T15:08:43.395489Z","iopub.status.idle":"2022-12-17T15:08:44.563037Z","shell.execute_reply.started":"2022-12-17T15:08:43.395451Z","shell.execute_reply":"2022-12-17T15:08:44.561861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ImageMask(torch.utils.data.Dataset):\n    def __init__(self, dataset, image_size=(3,64,64),param=0.4):\n        self.dataset = dataset\n        self.image_size = image_size\n        self.image_shape = (image_size[1],image_size[2])\n        self.map = ['left','random','center','box','up','down']\n        self.param = param\n  \n    def __getitem__(self, index):\n        target_image = self.dataset[index][0]\n        assert(torch.is_tensor(target_image))\n\n        maskType = self.map[index%4]\n        mask = np.ones(self.image_shape)\n        if index%8==0:\n            maskType = 'right'\n    \n\n        param = 0.6\n        if maskType == 'random':\n            mask[np.random.random(self.image_shape) < param] = 0.0\n        elif maskType == 'center':\n            centerScale = 0.3\n            sz = tuple([(int)(z * centerScale) for z in self.image_shape])\n            mask[ sz[1]:-sz[1], sz[0]:-sz[0]] = 0.0\n        elif maskType == 'left':\n            sz = np.random.randint(10,64-35,size=(2,))\n            mask[sz[0]:sz[0]+10,sz[1]:sz[1]+30] = 0.0\n        elif maskType == 'right':\n            sz = np.random.randint(10,64-35,size=(2,))\n            mask[sz[1]:sz[1]+30,sz[0]:sz[0]+10] = 0.0\n        elif maskType == 'box':\n            sz = np.random.randint(10,64-20,size=(3,2))\n            mask[sz[0][0]:sz[0][0]+10,sz[0][1]:sz[0][1]+10] = 0.0\n            mask[sz[1][0]:sz[1][0]+10,sz[1][1]:sz[1][1]+10] = 0.0\n            mask[sz[2][0]:sz[2][0]+10,sz[2][1]:sz[2][1]+10] = 0.0\n        elif maskType == 'up':\n            c = self.image_shape[0] // 2\n            mask[:,:c] = 0.0\n        elif maskType == 'down':\n            c = self.image_shape[0] // 2\n            mask[:,c:] = 0.0\n        else:\n            assert(False)\n\n        return (target_image, torch.FloatTensor(mask),maskType)\n  \n    def __len__(self):\n        return len(self.dataset)","metadata":{"execution":{"iopub.status.busy":"2022-12-17T15:08:44.569111Z","iopub.execute_input":"2022-12-17T15:08:44.572509Z","iopub.status.idle":"2022-12-17T15:08:44.597273Z","shell.execute_reply.started":"2022-12-17T15:08:44.572461Z","shell.execute_reply":"2022-12-17T15:08:44.595991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_ = dset.ImageFolder(root=root_data, transform=transforms.Compose([\n                               transforms.Resize(image_size),\n                               transforms.CenterCrop(image_size),\n                               transforms.ToTensor(),\n                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n                           ]))\nmasked_dataset_ = ImageMask(dataset_)\nmasked_loader = torch.utils.data.DataLoader(masked_dataset_, batch_size=12,\n                                         shuffle=False,drop_last=True ,num_workers=2,pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2022-12-17T15:08:44.601599Z","iopub.execute_input":"2022-12-17T15:08:44.602186Z","iopub.status.idle":"2022-12-17T15:12:04.541361Z","shell.execute_reply.started":"2022-12-17T15:08:44.602124Z","shell.execute_reply":"2022-12-17T15:12:04.540421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"WINDOW_SIZE = 7\nprior_loss_parameter = 0.003\nspecial_conv = torch.ones(1,1,WINDOW_SIZE,WINDOW_SIZE,device=device)","metadata":{"execution":{"iopub.status.busy":"2022-12-17T15:12:04.544295Z","iopub.execute_input":"2022-12-17T15:12:04.545134Z","iopub.status.idle":"2022-12-17T15:12:04.550213Z","shell.execute_reply.started":"2022-12-17T15:12:04.545096Z","shell.execute_reply":"2022-12-17T15:12:04.549175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import scipy.sparse\nimport os\nimport PIL.Image\nimport torch\nfrom torchvision.transforms import ToPILImage,ToTensor\ntry:\n    import pyamg\nexcept:\n    os.system(\"pip3 install pyamg\")\nimport pyamg\n\n\ndef convert_to_np(pic):\n    npimg = None\n    if isinstance(pic, torch.FloatTensor):\n        pic = pic.mul(255).byte()\n    if isinstance(pic, torch.Tensor):\n        npimg = np.transpose(pic.numpy(), (1, 2, 0))\n        \n    assert npimg is not None\n    \n    return npimg\n\n\n# pre-process the mask array so that uint64 types from opencv.imread can be adapted\ndef unnormalise(img):\n    return img/2 + 0.5\n\ndef poissonblending_batch(og_batch,gan_batch,mask_inv_batch):\n    out = torch.zeros_like(gan_batch)\n    i = 0\n    for og,gan,mask_inv in zip(og_batch,gan_batch,mask_inv_batch):\n        out[i,:,:,:] = ToTensor()(poissonblending_fromcpu(og,gan,mask_inv))\n        i += 1\n        \n    return out\n        \n\ndef poissonblending_fromcpu(imgt, imgs, mask):\n    mask = convert_to_np(mask)\n    mask = np.squeeze(mask)\n    imgt = convert_to_np(imgt)\n    imgs = convert_to_np(imgs)\n    \n    assert imgs.shape==(64,64,3)\n    assert mask.shape==(64,64)\n    \n    assert np.min(mask)==0 \n    assert np.max(mask)==255\n    \n    return blend(imgt, imgs,mask)\n\ndef blend(img_target, img_source, img_mask, offset=(0, 0)):\n    # compute regions to be blended\n    region_source = (0,0,64,64)\n    region_target = (0,0,64,64)\n    region_size = (region_source[2]-region_source[0], region_source[3]-region_source[1])\n\n    # clip and normalize mask image\n    img_mask[img_mask==0] = False\n    img_mask[img_mask!=False] = True\n\n\n    # create coefficient matrix\n    A = scipy.sparse.identity(np.prod(region_size), format='lil')\n    for y in range(region_size[0]):\n        for x in range(region_size[1]):\n            if img_mask[y,x]:\n                index = x+y*region_size[1]\n                A[index, index] = 4\n                if index+1 < np.prod(region_size):\n                    A[index, index+1] = -1\n                if index-1 >= 0:\n                    A[index, index-1] = -1\n                if index+region_size[1] < np.prod(region_size):\n                    A[index, index+region_size[1]] = -1\n                if index-region_size[1] >= 0:\n                    A[index, index-region_size[1]] = -1\n    A = A.tocsr()\n    \n    # create poisson matrix for b\n    P = pyamg.gallery.poisson(img_mask.shape)\n\n    # for each layer (ex. RGB)\n    for num_layer in range(img_target.shape[2]):\n        # get subimages\n        t = img_target[region_target[0]:region_target[2],region_target[1]:region_target[3],num_layer]\n        s = img_source[region_source[0]:region_source[2], region_source[1]:region_source[3],num_layer]\n        t = t.flatten()\n        s = s.flatten()\n\n        # create b\n        b = P * s\n        for y in range(region_size[0]):\n            for x in range(region_size[1]):\n                if not img_mask[y,x]:\n                    index = x+y*region_size[1]\n                    b[index] = t[index]\n\n        # solve Ax = b\n        x = pyamg.solve(A,b,verb=False,tol=1e-10)\n\n        # assign x to target image\n        x = np.reshape(x, region_size)\n        x[x>255] = 255\n        x[x<0] = 0\n        x = np.array(x, img_target.dtype)\n        img_target[region_target[0]:region_target[2],region_target[1]:region_target[3],num_layer] = x\n\n    return img_target\n\nprint(\"=====DONE=====\")","metadata":{"execution":{"iopub.status.busy":"2022-12-17T15:17:19.297252Z","iopub.execute_input":"2022-12-17T15:17:19.297649Z","iopub.status.idle":"2022-12-17T15:17:19.319318Z","shell.execute_reply.started":"2022-12-17T15:17:19.297608Z","shell.execute_reply":"2022-12-17T15:17:19.318189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ntry:\n    import piq\nexcept:\n    os.system(\"pip3 install piq\")\n        \nfrom piq import psnr,ssim,multi_scale_ssim\nfrom typing import Union, Tuple\nimport time\ninpaint_iters=1800\ninpainted_images_gan = None\nimage_batch = None\ninpainted_images= None\nmasks = None\nssim_index = torch.zeros(len(masked_loader),12)\npsnr_index = torch.zeros(len(masked_loader),12)\n\nfor i,data in enumerate(masked_loader,0):\n    \n    b_size = data[0].size(0)\n    image_batch_cpu = unnormalise(data[0]) # unnormalise cpu tensor\n    image_batch = data[0].to(device)\n    masks_cpu = data[1].unsqueeze(1)\n    masks = data[1].to(device).unsqueeze(1)\n    masks_inv = torch.ones_like(masks) - masks\n    masks_inv_cpu = torch.ones_like(masks_cpu) - masks_cpu\n    \n    weighted_masks = (torch.nn.functional.conv2d(masks_inv,special_conv,padding=WINDOW_SIZE//2)*masks)/(WINDOW_SIZE*WINDOW_SIZE)\n\n    z_closest = torch.randn(b_size,noise_dim,1,1,device=device,requires_grad=True)\n    z_optimizer = torch.optim.Adam([z_closest])\n    \n    prior_criterior = nn.BCEWithLogitsLoss()\n    p_losses=[]\n    c_losses=[]\n    start_time = time.time()\n    for j in range(inpaint_iters):\n        z_optimizer.zero_grad()\n        fake_images = Gen_eval(z_closest)\n        d_output = Dis_eval(fake_images).view(-1)\n\n        prior_loss= 64*64*3*prior_loss_parameter*prior_criterior(d_output,torch.ones(b_size,device=device))\n\n        context_loss = torch.norm(weighted_masks*(fake_images - image_batch),p=1)\n        if (j % 50):\n            p_losses.append(prior_loss.detach().cpu())\n            c_losses.append(context_loss.detach().cpu())\n            \n        loss = context_loss + prior_loss\n        loss.backward()\n        z_optimizer.step()\n    inpainted_images_gan_cpu = unnormalise(Gen_eval(z_closest.detach()).cpu())\n    # returns a torch tensor of images\n    mid_time = time.time()\n    inpainted_images_cpu = poissonblending_batch(image_batch_cpu,inpainted_images_gan_cpu,masks_inv_cpu)\n    inpainted_images = inpainted_images_cpu.to(device)\n    ssim_index[i,:] = ssim(inpainted_images,unnormalise(image_batch),data_range=1.).cpu()\n    psnr_index[i,:] = psnr(inpainted_images_cpu,image_batch_cpu,data_range=1.,reduction='none')\n    end_time = time.time()\n    for img,gen_img,gen_poisson,mask in zip(image_batch_cpu,inpainted_images_gan_cpu,inpainted_images_cpu,masks_cpu):\n#     for img, mask in zip(image_batch_cpu, masks_cpu):\n        og = transforms.ToPILImage(mode=\"RGB\")(img)\n        inp = transforms.ToPILImage(mode=\"RGB\")(img*mask + (1-mask)*gen_img)\n        inpp = transforms.ToPILImage(mode=\"RGB\")(gen_poisson)\n        ogm = transforms.ToPILImage(mode=\"RGB\")(img*mask)\n        f = plt.figure(figsize=(7, 4))\n        f.add_subplot(1,2, 1).set_title('Original')\n        plt.imshow(og)\n        plt.axis('off')\n        f.add_subplot(1,2, 2).set_title('Masked')\n        plt.imshow(ogm)\n        plt.axis('off')\n        f.add_subplot(1,4, 3).set_title('Overlay')\n        plt.imshow(inp)\n        plt.axis('off')\n        f.add_subplot(1,4, 4).set_title('Inpainted')\n        plt.imshow(inpp)\n        plt.axis('off')\n        plt.show()\n        \n    if i==5:\n        break","metadata":{"execution":{"iopub.status.busy":"2022-12-17T15:17:54.384863Z","iopub.execute_input":"2022-12-17T15:17:54.385251Z","iopub.status.idle":"2022-12-17T15:17:59.334715Z","shell.execute_reply.started":"2022-12-17T15:17:54.385217Z","shell.execute_reply":"2022-12-17T15:17:59.333483Z"},"trusted":true},"execution_count":null,"outputs":[]}]}