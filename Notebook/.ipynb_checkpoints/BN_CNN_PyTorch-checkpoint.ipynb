{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "studied-offense",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-06-13T15:59:56.705826Z",
     "iopub.status.busy": "2021-06-13T15:59:56.705172Z",
     "iopub.status.idle": "2021-06-13T15:59:59.398434Z",
     "shell.execute_reply": "2021-06-13T15:59:59.397448Z",
     "shell.execute_reply.started": "2021-06-11T11:48:01.658423Z"
    },
    "papermill": {
     "duration": 2.724743,
     "end_time": "2021-06-13T15:59:59.398604",
     "exception": false,
     "start_time": "2021-06-13T15:59:56.673861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from torch.optim import Adam\n",
    "from torchvision import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():        \n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pacific-billion",
   "metadata": {
    "papermill": {
     "duration": 0.01603,
     "end_time": "2021-06-13T15:59:59.432365",
     "exception": false,
     "start_time": "2021-06-13T15:59:59.416335",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Prepare The Image Data (As Before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "mighty-mongolia",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T15:59:59.472367Z",
     "iopub.status.busy": "2021-06-13T15:59:59.471623Z",
     "iopub.status.idle": "2021-06-13T16:00:05.365931Z",
     "shell.execute_reply": "2021-06-13T16:00:05.365343Z",
     "shell.execute_reply.started": "2021-06-11T11:48:03.897425Z"
    },
    "papermill": {
     "duration": 5.918207,
     "end_time": "2021-06-13T16:00:05.366081",
     "exception": false,
     "start_time": "2021-06-13T15:59:59.447874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_path(tup):\n",
    "    return tup[0]\n",
    "\n",
    "train = datasets.ImageFolder(\"data/cat-and-dog/training_set\")\n",
    "train_imgs = pd.Series(train.imgs, name=\"path\").apply(func=extract_path)\n",
    "train_targets = pd.Series(train.targets, name=\"label\")\n",
    "train_merged = pd.concat([train_imgs, train_targets], axis=1)\n",
    "train, val = train_test_split(train_merged, test_size=0.3, random_state=0)\n",
    "\n",
    "test = datasets.ImageFolder(\"data/cat-and-dog/test_set\")\n",
    "test_imgs = pd.Series(test.imgs, name=\"path\").apply(func=extract_path)\n",
    "test_targets = pd.Series(test.targets, name=\"label\")\n",
    "test_merged = pd.concat([test_imgs, test_targets], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-treat",
   "metadata": {
    "papermill": {
     "duration": 0.015826,
     "end_time": "2021-06-13T16:00:05.399434",
     "exception": false,
     "start_time": "2021-06-13T16:00:05.383608",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Take a look at the target distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "virtual-browse",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T16:00:05.440399Z",
     "iopub.status.busy": "2021-06-13T16:00:05.439292Z",
     "iopub.status.idle": "2021-06-13T16:00:05.464392Z",
     "shell.execute_reply": "2021-06-13T16:00:05.463831Z",
     "shell.execute_reply.started": "2021-06-11T11:48:14.324249Z"
    },
    "papermill": {
     "duration": 0.048985,
     "end_time": "2021-06-13T16:00:05.464511",
     "exception": false,
     "start_time": "2021-06-13T16:00:05.415526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.500803\n",
       "0    0.499197\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"label\"].value_counts()/len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "renewable-mistress",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T16:00:05.507827Z",
     "iopub.status.busy": "2021-06-13T16:00:05.506783Z",
     "iopub.status.idle": "2021-06-13T16:00:05.511586Z",
     "shell.execute_reply": "2021-06-13T16:00:05.511082Z",
     "shell.execute_reply.started": "2021-06-11T11:48:14.354456Z"
    },
    "papermill": {
     "duration": 0.029654,
     "end_time": "2021-06-13T16:00:05.511749",
     "exception": false,
     "start_time": "2021-06-13T16:00:05.482095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.500833\n",
       "1    0.499167\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val[\"label\"].value_counts()/len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "adequate-silver",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T16:00:05.554184Z",
     "iopub.status.busy": "2021-06-13T16:00:05.553177Z",
     "iopub.status.idle": "2021-06-13T16:00:05.556396Z",
     "shell.execute_reply": "2021-06-13T16:00:05.556887Z",
     "shell.execute_reply.started": "2021-06-11T11:48:14.36704Z"
    },
    "papermill": {
     "duration": 0.028363,
     "end_time": "2021-06-13T16:00:05.557072",
     "exception": false,
     "start_time": "2021-06-13T16:00:05.528709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A custom image dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, data, transform_pipe, device):\n",
    "        self.data = data\n",
    "        self.transform_pipe = transform_pipe\n",
    "        self.device = device\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        observation = self.data.iloc[index, :]\n",
    "        image = Image.open(observation[\"path\"]).convert(\"RGB\")\n",
    "        image = self.transform_pipe(image).to(self.device)\n",
    "        if observation[\"label\"] == 0:\n",
    "            label = torch.zeros(size=(1,1)).to(self.device)\n",
    "        else:\n",
    "            label = torch.ones(size=(1,1)).to(self.device)\n",
    "        return [image, label]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-trinidad",
   "metadata": {
    "papermill": {
     "duration": 0.017031,
     "end_time": "2021-06-13T16:00:05.591979",
     "exception": false,
     "start_time": "2021-06-13T16:00:05.574948",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Batch Normalization Introduction\n",
    "\n",
    "To understand the concept of [Batch Normalization](http://proceedings.mlr.press/v37/ioffe15.pdf), we should step back and think about Normalization (often referred to as Standardization) itself.\n",
    "Normalization...\n",
    "\n",
    "* ...refers to adjusting numerical values to be on a common scale.\n",
    "\n",
    "* ...allows our model to be more generalizing\n",
    "\n",
    "Batch Normalization utilizes a Normalization technique similar to [Standardization](https://www.kaggle.com/milankalkenings/comprehensive-tutorial-feature-engineering).\n",
    "Standardization subtracts the mean of the data and devides it by its standard deviation. The normalization technique used by Batch Normalization subtracts the mean of the data and devides it by the variance of the data\n",
    "\n",
    "## How does Batch Normalization work?\n",
    "\n",
    "Whenever we train a deep learning model, the parameters in each layer are adapted over the training iterations. In iteration $\\mathscr{i}$, the parameters of layer $\\mathscr{l}$ will be adapted to generate optimal outputs for the given input. However, training the model will change the input of layer $\\mathscr{l}$, since the parameters of layer $\\mathscr{l-1}$ will be changed as well. Thus, the parameters of layer $\\mathscr{l}$ are already slightly outdated in iteration $\\mathscr{i}+1$. The aforementioned change in the input distribution is reffered to as [Internal Covariance Shift](http://proceedings.mlr.press/v37/ioffe15.pdf) (note: the more general term [Covariance Shift](https://www.youtube.com/watch?v=nUUqwaxLnWs&t=64s) refers to changes in our data that require retraining the model).\n",
    "Batch Normalization evades this issue by performing Standardization per batch at the given position in the network using the following formulas using $N$ many inputs:\n",
    "\n",
    "$\\mu_{batch}=\\frac{1}{N}\\sum^N_nx_n$\n",
    "\n",
    "$\\sigma_{batch}^2=\\frac{1}{N}\\sum^N_n(x_n-\\mu_{batch})^2$\n",
    "\n",
    "$\\hat x_n=\\frac{x_n-\\mu_{batch}}{\\sqrt{\\sigma^2 + \\epsilon}}$\n",
    "\n",
    "return: $\\gamma \\hat x_n + \\beta$\n",
    "\n",
    "Note: $\\gamma \\hat x_n + \\beta$ is solely used to allow the network to learn its optimal mean $\\beta$ and deviation $\\gamma$ on its own. Both parameters are learned during the training process.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "For those of you who already made some experiences with Machine Learning Ensembles:\n",
    "\n",
    "Interpreting each node in our neural network as an **isolated** weak learner in a stacking ensemble, we can easily derive the idea of batch normalization.\n",
    "The nodes (weak learners) at layer $\\mathscr{l}$ don't know wether the outputs of layer $\\mathscr{l-1}$ are the actual input data (in case $\\mathscr{l-1} = 0$) or already processed data from any hidden layer. \n",
    "Since we know that normalization in many cases improves the performance of machine learning models by allowing them to be more generalizing, we should enable all of these weak learners to benefit from that. \n",
    "Thus, normalizing the data for each (or at least for some to have less time complexity) non-input layer seems to be a good idea. \n",
    "Since we only feed batches into our neural network, we have no idea about the actual normalization parameters across the whole dataset and instead can only predict them on the given batch - we arrived at the idea of batch normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "democratic-kennedy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-11T07:46:46.17757Z",
     "iopub.status.busy": "2021-06-11T07:46:46.175655Z",
     "iopub.status.idle": "2021-06-11T07:46:46.193762Z",
     "shell.execute_reply": "2021-06-11T07:46:46.191567Z",
     "shell.execute_reply.started": "2021-06-11T07:46:46.177095Z"
    },
    "papermill": {
     "duration": 0.016943,
     "end_time": "2021-06-13T16:00:05.627446",
     "exception": false,
     "start_time": "2021-06-13T16:00:05.610503",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Benefits of Batch Normalization\n",
    "\n",
    "The [Batch Normalization Paper](http://proceedings.mlr.press/v37/ioffe15.pdf) lists a number of practical beneftis. \n",
    "\n",
    "* Batch Normalization allows layers to learn slightly more independently from other layers.\n",
    "\n",
    "* Batch Normalization reduces the impact of the data scale on the gradients, making them more dependend on the actual patterns in the input and less on single large values.\n",
    "\n",
    "* Each layer can assume its input to be equally distributed on train and test\n",
    "\n",
    "* The model will be less sensitive to parameter initialization.\n",
    "\n",
    "* The resulting gradients are more balanced and thus less likely to explode or vanish. Exploding and vanishing gradients are caused by backpropagation itself. To reach weights in the early layers of our model, we need to apply the chain rule all the way down to the respective weights. Let me give you an extreme example for each case: If the values in the chain rule are all bigger than 1, the respective gradient might be really big (explode). If the values in the chain rule are all smaller than 1, the respective gradient might be very small. Since the gradients are directly used in the parameter updates, they might lead to way too big (exploding), or way too small updates during the training process. The earlier the weights are used in the neural network, the more are they at risk to suffer from the aforementioned issues.\n",
    "\n",
    "* The model can handle higher learning rates (because Batch Normalization evades vanishing and exploding gradient).\n",
    "\n",
    "* Batch Normalization prevents saturable nonlinearity functions to saturate (not that important for us but beneficial in very complex architectures that rely on specific nonlinearities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-retro",
   "metadata": {
    "papermill": {
     "duration": 0.016697,
     "end_time": "2021-06-13T16:00:05.661421",
     "exception": false,
     "start_time": "2021-06-13T16:00:05.644724",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Implementing Batch Normalization\n",
    "\n",
    "Note: Batch Normalization can be applied to image data as well. Therefore we solely have to use `BatchNorm2d` and provide the number of image channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ahead-barrier",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T16:00:05.710168Z",
     "iopub.status.busy": "2021-06-13T16:00:05.709225Z",
     "iopub.status.idle": "2021-06-13T16:00:05.712980Z",
     "shell.execute_reply": "2021-06-13T16:00:05.713437Z",
     "shell.execute_reply.started": "2021-06-11T11:48:14.376932Z"
    },
    "papermill": {
     "duration": 0.035064,
     "end_time": "2021-06-13T16:00:05.713583",
     "exception": false,
     "start_time": "2021-06-13T16:00:05.678519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNNClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    A CNN-based classifier.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, conv_ch1, conv_ch2, linear_size, kernel_size, pooling_size, linear_input_size=None):\n",
    "        \"\"\"\n",
    "        Constructor.\n",
    "\n",
    "        :param int conv_ch1: number of output channels of the first convolutional layer\n",
    "        :param int conv_ch2: number of output channels of the second convolutional layer\n",
    "        :param int linear_size: number of outputs the second linear layer expects from the first linear layer\n",
    "        :param int kernel_size: width and height of each convolutional kernel in the model\n",
    "        :param int pooling_size: size of the pooling window\n",
    "        :param int linear_input_size: number of outputs the first linear layer expects from the convolutional\n",
    "        part.\n",
    "        \"\"\"\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        self.linear_input_size = linear_input_size\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(pooling_size)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=conv_ch1, kernel_size=kernel_size)\n",
    "        \n",
    "        self.batch_norm1 = nn.BatchNorm2d(num_features=conv_ch1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=conv_ch1, out_channels=conv_ch2, kernel_size=kernel_size)\n",
    "        \n",
    "        if linear_input_size:  # evaluates as False if linear_input_size is None\n",
    "            self.batch_norm2 = nn.BatchNorm1d(num_features=linear_input_size)\n",
    "            self.linear1 = nn.Linear(in_features=linear_input_size, out_features=linear_size)\n",
    "            self.batch_norm3 = nn.BatchNorm1d(num_features=linear_size)\n",
    "            self.linear2 = nn.Linear(in_features=linear_size, out_features=1)\n",
    "            self.batch_norm4 = nn.BatchNorm1d(num_features=1)\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def conv_part(self, x):\n",
    "        \"\"\"\n",
    "        Calculates the convolutional part of the forward pass.\n",
    "\n",
    "        :param torch.Tensor x: input data\n",
    "        :return: input representations after the convolutional part.\n",
    "        \"\"\"\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        return x\n",
    "\n",
    "    def scalars_after_conv(self, x):\n",
    "        \"\"\"\n",
    "        Calculates how many scalars, i.e. tensors of rank 0 are in the output of the convolutional component.\n",
    "\n",
    "        :param torch.Tensor x: one batch of input/observations\n",
    "        :return: the number of rank 0 tensors in the output of the convolutional component\n",
    "        \"\"\"\n",
    "        x = self.conv_part(x)\n",
    "        size = x.size()  # batch_size x channel_size x width x height\n",
    "        n_channels = size[1]\n",
    "        width = size[2]\n",
    "        height = size[3]\n",
    "        return n_channels * width * height\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        performs the forward pass.\n",
    "\n",
    "        :param  torch.Tensor x: the input/observations per batch\n",
    "        :return: the prediction of the whole batch\n",
    "        \"\"\"\n",
    "        x = self.conv_part(x)\n",
    "\n",
    "        if self.linear_input_size:\n",
    "            x = x.view(-1, self.linear_input_size)  # flatten out for the linear layers\n",
    "            \n",
    "            x = self.batch_norm2(x)\n",
    "            x = self.linear1(x)\n",
    "            \n",
    "            x = self.batch_norm3(x)\n",
    "            x = self.linear2(x)\n",
    "            \n",
    "            x = self.batch_norm4(x)\n",
    "        return self.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-residence",
   "metadata": {
    "papermill": {
     "duration": 0.016805,
     "end_time": "2021-06-13T16:00:05.747542",
     "exception": false,
     "start_time": "2021-06-13T16:00:05.730737",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Image Normalization\n",
    "Now that we created a batch-normalized neural network, we should normalize the image data itself as well. We could either do this by aplying batch normalization before the first hidden layer, or use `transforms.Normalize` in our data preprocessing pipeline. I will stick to the latter in order to normalize over the whole dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "global-lease",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T16:00:05.792332Z",
     "iopub.status.busy": "2021-06-13T16:00:05.790257Z",
     "iopub.status.idle": "2021-06-13T16:00:05.793297Z",
     "shell.execute_reply": "2021-06-13T16:00:05.793819Z",
     "shell.execute_reply.started": "2021-06-11T11:48:14.394236Z"
    },
    "papermill": {
     "duration": 0.029628,
     "end_time": "2021-06-13T16:00:05.793954",
     "exception": false,
     "start_time": "2021-06-13T16:00:05.764326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_mean_std(loader):\n",
    "    \"\"\"\n",
    "    Calculates the averaged mean and std for all channels \n",
    "    of a given RGB-image dataset.\n",
    "    \"\"\"\n",
    "    mean_ch1 = 0\n",
    "    mean_ch2 = 0\n",
    "    mean_ch3 = 0\n",
    "    std_ch1 = 0\n",
    "    std_ch2 = 0\n",
    "    std_ch3 = 0\n",
    "\n",
    "\n",
    "    for image in loader:\n",
    "        means = torch.mean(input=image[0], dim=[2, 3])[0] # mean for each channel\n",
    "        mean_ch1 += means[0].item()\n",
    "        mean_ch2 += means[1].item()\n",
    "        mean_ch3 += means[2].item()\n",
    "\n",
    "        stds = torch.std(input=image[0], dim=[2, 3])[0] # std for each channel\n",
    "        std_ch1 += stds[0].item()\n",
    "        std_ch2 += stds[1].item()\n",
    "        std_ch3 += stds[2].item()\n",
    "        \n",
    "    mean_ch1 /= len(loader)\n",
    "    mean_ch2 /= len(loader)\n",
    "    mean_ch3 /= len(loader)\n",
    "    std_ch1 /= len(loader)\n",
    "    std_ch2 /= len(loader)\n",
    "    std_ch3 /= len(loader)\n",
    "    return {\"mean\": [mean_ch1, mean_ch2, mean_ch3], \"std\": [std_ch1, std_ch2, std_ch3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "latter-default",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T16:00:05.836469Z",
     "iopub.status.busy": "2021-06-13T16:00:05.835903Z",
     "iopub.status.idle": "2021-06-13T16:00:59.740488Z",
     "shell.execute_reply": "2021-06-13T16:00:59.739866Z",
     "shell.execute_reply.started": "2021-06-11T11:48:14.408943Z"
    },
    "papermill": {
     "duration": 53.930204,
     "end_time": "2021-06-13T16:00:59.740662",
     "exception": false,
     "start_time": "2021-06-13T16:00:05.810458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# determine mean and std of the training data\n",
    "example_pipe = transforms.Compose([transforms.RandomCrop(size=[256, 256], pad_if_needed=True),\n",
    "                                   transforms.ToTensor()])\n",
    "\n",
    "example_dataset = CustomDataset(data=train, transform_pipe=example_pipe, device=device)\n",
    "example_loader = DataLoader(example_dataset, \n",
    "                            batch_size=1, \n",
    "                            sampler=RandomSampler(data_source=example_dataset))\n",
    "\n",
    "stats = find_mean_std(loader=example_loader)\n",
    "\n",
    "# define the datasets accordingly\n",
    "transform_pipe = transforms.Compose([transforms.RandomCrop(size=[256, 256], pad_if_needed=True),\n",
    "                                     transforms.ToTensor(), \n",
    "                                     transforms.Normalize(mean=stats[\"mean\"], std=stats[\"std\"])])\n",
    "\n",
    "train_dataset = CustomDataset(data=train, transform_pipe=transform_pipe, device=device)\n",
    "val_dataset = CustomDataset(data=val, transform_pipe=transform_pipe, device=device)\n",
    "test_dataset = CustomDataset(data=test, transform_pipe=transform_pipe, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-default",
   "metadata": {
    "papermill": {
     "duration": 0.017037,
     "end_time": "2021-06-13T16:00:59.775315",
     "exception": false,
     "start_time": "2021-06-13T16:00:59.758278",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training\n",
    "Using Gradient Accumulation as mentioned in the last part of this series.\n",
    "Consider we have a GPU capable to load 8 images at a time only, but we want to calculate gradients based on a pseudo batch of 16 images per step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "confident-manor",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T16:00:59.818364Z",
     "iopub.status.busy": "2021-06-13T16:00:59.817529Z",
     "iopub.status.idle": "2021-06-13T16:01:00.843274Z",
     "shell.execute_reply": "2021-06-13T16:01:00.842717Z",
     "shell.execute_reply.started": "2021-06-11T11:49:10.652952Z"
    },
    "papermill": {
     "duration": 1.0514,
     "end_time": "2021-06-13T16:01:00.843448",
     "exception": false,
     "start_time": "2021-06-13T16:00:59.792048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "# accumulate 4 4-batches to one 16-pseudo-batch\n",
    "combine = 4\n",
    "batch_size = 4\n",
    "\n",
    "n_epochs = 5\n",
    "lr = 0.01  # note: large learning rate\n",
    "conv_ch1 = 8\n",
    "conv_ch2 = 4\n",
    "linear_size = 16\n",
    "kernel_size = 3\n",
    "pooling_size = 4\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=batch_size, \n",
    "                          sampler=RandomSampler(data_source=train_dataset))\n",
    "val_loader = DataLoader(val_dataset, \n",
    "                        batch_size=batch_size, \n",
    "                        sampler=RandomSampler(data_source=val_dataset))\n",
    "\n",
    "# to automatically determine the first linear size:\n",
    "example_batch = next(iter(train_loader))\n",
    "example_x = example_batch[0]\n",
    "example_model = CNNClassifier(conv_ch1=conv_ch1, \n",
    "                              conv_ch2=conv_ch2, \n",
    "                              linear_size=linear_size, \n",
    "                              kernel_size=kernel_size, \n",
    "                              pooling_size=pooling_size).to(device)\n",
    "linear_input_size = example_model.scalars_after_conv(x=example_x)\n",
    "\n",
    "model = CNNClassifier(conv_ch1=conv_ch1, \n",
    "                      conv_ch2=conv_ch2, \n",
    "                      linear_size=linear_size, \n",
    "                      kernel_size=kernel_size, \n",
    "                      pooling_size=pooling_size, \n",
    "                      linear_input_size=linear_input_size).to(device)\n",
    "optimizer = Adam(model.parameters())\n",
    "loss_func = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "threatened-coverage",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T16:01:00.890582Z",
     "iopub.status.busy": "2021-06-13T16:01:00.889745Z",
     "iopub.status.idle": "2021-06-13T16:07:47.056461Z",
     "shell.execute_reply": "2021-06-13T16:07:47.055916Z",
     "shell.execute_reply.started": "2021-06-11T11:49:11.672541Z"
    },
    "papermill": {
     "duration": 406.196495,
     "end_time": "2021-06-13T16:07:47.056619",
     "exception": false,
     "start_time": "2021-06-13T16:01:00.860124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch 1 ===\n",
      "Train Accuracy: 0.6045086842731382\n",
      "Val Accuracy: 0.598585690515807 \n",
      "\n",
      "=== Epoch 2 ===\n",
      "Train Accuracy: 0.6109326671425173\n",
      "Val Accuracy: 0.598585690515807 \n",
      "\n",
      "=== Epoch 3 ===\n",
      "Train Accuracy: 0.6290149892933619\n",
      "Val Accuracy: 0.6335274542429284 \n",
      "\n",
      "=== Epoch 4 ===\n",
      "Train Accuracy: 0.6345467523197716\n",
      "Val Accuracy: 0.6372712146422629 \n",
      "\n",
      "=== Epoch 5 ===\n",
      "Train Accuracy: 0.6344872709969069\n",
      "Val Accuracy: 0.6397670549084858 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    print(\"=== Epoch\", epoch+1, \"===\")\n",
    "    acc_train = 0\n",
    "    acc_val = 0\n",
    "    # train\n",
    "    model.train()  # train mode\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        x = batch[0]\n",
    "        y = batch[1].view(-1, 1)\n",
    "        \n",
    "        probas = model(x) # perform forward\n",
    "        loss = loss_func(probas, y) # calculate the loss\n",
    "        loss /= combine\n",
    "        loss.backward() # calculate gradients\n",
    "        \n",
    "        if ((i+1) % combine == 0):\n",
    "            optimizer.step() # update weights\n",
    "            optimizer.zero_grad() # clear the gradient\n",
    "            \n",
    "    model.eval()  # evaluation mode\n",
    "    # acc on train, interesting if you want to\n",
    "    # check for overfitting\n",
    "    for batch in train_loader:\n",
    "        x = batch[0]\n",
    "        y = batch[1].view(-1, 1)\n",
    "        with torch.no_grad():\n",
    "            probas = model(x)\n",
    "        pred = np.round(probas.cpu().numpy())\n",
    "        acc_train += accuracy_score(y_true=y.cpu().numpy(), y_pred=pred)\n",
    "    acc_train /= len(train_loader)\n",
    "    print(\"Train Accuracy:\", acc_train)\n",
    "    \n",
    "    # acc on val\n",
    "    for batch in val_loader:\n",
    "        x = batch[0]\n",
    "        y = batch[1].view(-1, 1)\n",
    "        with torch.no_grad():\n",
    "            probas = model(x)\n",
    "        pred = np.round(probas.cpu().numpy())\n",
    "        acc_val += accuracy_score(y_true=y.cpu().numpy(), y_pred=pred)\n",
    "        \n",
    "    \n",
    "    acc_val /= len(val_loader)\n",
    "    print(\"Val Accuracy:\", acc_val, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166fbcab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 479.980196,
   "end_time": "2021-06-13T16:07:48.639251",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-13T15:59:48.659055",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
