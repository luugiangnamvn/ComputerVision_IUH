{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bbd0c74",
   "metadata": {},
   "source": [
    "# Colorspaces\n",
    "\n",
    "Let's have a brief introduction into converting to different colorspaces! The video goes into more detail about colorspaces.\n",
    "\n",
    "Quick Info Link: \n",
    "https://en.wikipedia.org/wiki/HSL_and_HSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628b4c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ed139f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../DATA/00-puppy.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e82aea",
   "metadata": {},
   "source": [
    "### Converting to Different Colorspaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d303b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ee4277",
   "metadata": {},
   "source": [
    "**Converting to HSV**\n",
    "https://en.wikipedia.org/wiki/HSL_and_HSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3282ba84",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d922a7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../DATA/00-puppy.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8d9225",
   "metadata": {},
   "source": [
    "# Blending and Pasting Images\n",
    "\n",
    "For some computer vision systems, we'll want to be able to post our own image on top of an already existing image or video. We may also want to blend images, maybe we want to have a \"highlight\" effect instead of just a solid box or empty rectangle.\n",
    "\n",
    "Let's explore what is commonly known as **Arithmetic Image Operations** with OpenCV. These are referred to as Arithmetic Operations because OpenCV is simply performing some common math with the pixels for the final effect. We'll see a bit of this in our code.\n",
    "\n",
    "## Blending Images\n",
    "\n",
    "Blending Images is actually quite simple, let's look at a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85069e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two images\n",
    "img1 = cv2.imread('../DATA/dog_backpack.png')\n",
    "img2 = cv2.imread('../DATA/watermark_no_copy.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8483d401",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd13c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ccdd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2aa384",
   "metadata": {},
   "source": [
    "Let's remember to fix the RGB!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bef4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196b9991",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59baad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcd9f40",
   "metadata": {},
   "source": [
    "### Resizing the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f296f060",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 =cv2.resize(img1,(1200,1200))\n",
    "img2 =cv2.resize(img2,(1200,1200))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08527261",
   "metadata": {},
   "source": [
    "Let's practice resizing the image, since the DO NOT COPY image is actually quite large 1200 by 1200, and our puppy in backpack image is 1400 by 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e6a070",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657de7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723d0980",
   "metadata": {},
   "source": [
    "### Blending the Image\n",
    "\n",
    "We will blend the values together with the formula:\n",
    "\n",
    "$$  img1 * \\alpha  + img2 * \\beta  + \\gamma $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22df0414",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3eb38ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688999ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "blended = cv2.addWeighted(src1=img1,alpha=0.7,src2=img2,beta=0.3,gamma=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665f0d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(blended)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa87429b",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Overlaying Images of Different Sizes\n",
    "\n",
    "We can use this quick trick to quickly overlap different sized images, by simply reassigning the larger image's values to match the smaller image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0740d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load two images\n",
    "img1 = cv2.imread('../DATA/dog_backpack.png')\n",
    "img2 = cv2.imread('../DATA/watermark_no_copy.png')\n",
    "img2 =cv2.resize(img2,(600,600))\n",
    "\n",
    "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "large_img = img1\n",
    "small_img = img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86130ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_offset=0\n",
    "y_offset=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56de9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_img[y_offset:y_offset+small_img.shape[0], x_offset:x_offset+small_img.shape[1]] = small_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e0cc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(large_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940a9ffc",
   "metadata": {},
   "source": [
    "## Blending Images of Different Sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0fe990",
   "metadata": {},
   "source": [
    "### Importing the images again and resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a625baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load two images\n",
    "img1 = cv2.imread('../DATA/dog_backpack.png')\n",
    "img2 = cv2.imread('../DATA/watermark_no_copy.png')\n",
    "img2 =cv2.resize(img2,(600,600))\n",
    "\n",
    "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d245f39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64996ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf99d2b9",
   "metadata": {},
   "source": [
    "### Create a Region of Interest (ROI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5542bb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4210baab",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_offset=934-600\n",
    "y_offset=1401-600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe4a6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an ROI of the same size of the foreground image (smaller image that will go on top)\n",
    "rows,cols,channels = img2.shape\n",
    "# roi = img1[0:rows, 0:cols ] # TOP LEFT CORNER\n",
    "roi = img1[y_offset:1401,x_offset:943] # BOTTOM RIGHT CORNER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4385173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4e9051",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee93bbf4",
   "metadata": {},
   "source": [
    "### Creating a Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dc8908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create a mask of logo and create its inverse mask also\n",
    "img2gray = cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534a6981",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2gray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3506e255",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img2gray,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5408a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_inv = cv2.bitwise_not(img2gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459383fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a50d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask_inv,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1618d462",
   "metadata": {},
   "source": [
    "## Convert Mask to have 3 channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501c84f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_background = np.full(img2.shape, 255, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292ce5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "bk = cv2.bitwise_or(white_background, white_background, mask=mask_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925ba3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aec364",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(bk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e417bb1",
   "metadata": {},
   "source": [
    "### Grab Original FG image and place on top of Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d25ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask_inv,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62154c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = cv2.bitwise_or(img2, img2, mask=mask_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae5affc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8acebff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c807f74",
   "metadata": {},
   "source": [
    "### Get ROI and blend in the mask with the ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a5e6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_roi = cv2.bitwise_or(roi,fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563d39aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(final_roi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10205a44",
   "metadata": {},
   "source": [
    "### Now add in the rest of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c8a69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_img = img1\n",
    "small_img = final_roi\n",
    "\n",
    "\n",
    "large_img[y_offset:y_offset+small_img.shape[0], x_offset:x_offset+small_img.shape[1]] = small_img\n",
    "\n",
    "plt.imshow(large_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf2e9e3",
   "metadata": {},
   "source": [
    "### Great Work!\n",
    "\n",
    "Check out these documentation examples and links for more help for these kinds of tasks (which can be really tricky!)\n",
    "\n",
    "1. https://stackoverflow.com/questions/10469235/opencv-apply-mask-to-a-color-image/38493075\n",
    "2. https://stackoverflow.com/questions/14063070/overlay-a-smaller-image-on-a-larger-image-python-opencv\n",
    "3. https://docs.opencv.org/3.4/d0/d86/tutorial_py_image_arithmetics.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59c7e2a",
   "metadata": {},
   "source": [
    "# Image Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c057043",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../DATA/rainbow.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea0a3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa852ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the 0 flag to read it in black and white\n",
    "img = cv2.imread('../DATA/rainbow.jpg',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5981da43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bf9b11",
   "metadata": {},
   "source": [
    "## Different Threshold Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd8dbc3",
   "metadata": {},
   "source": [
    "### Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e4f750",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,thresh1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba68781",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590ca793",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(thresh1,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5499ccc",
   "metadata": {},
   "source": [
    "### Binary Inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb6ec40",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,thresh2 = cv2.threshold(img,127,255,cv2.THRESH_BINARY_INV)\n",
    "plt.imshow(thresh2,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c7e1bd",
   "metadata": {},
   "source": [
    "###  Threshold Truncation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd56bee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,thresh3 = cv2.threshold(img,127,255,cv2.THRESH_TRUNC)\n",
    "plt.imshow(thresh3,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f6bfa0",
   "metadata": {},
   "source": [
    "### Threshold to Zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7e7b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,thresh4 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO)\n",
    "plt.imshow(thresh4,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd48d379",
   "metadata": {},
   "source": [
    "### Threshold to Zero (Inverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea98e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,thresh5 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO_INV)\n",
    "plt.imshow(thresh5,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90397eb",
   "metadata": {},
   "source": [
    "# Real World Applications\n",
    "\n",
    "## Adaptive Thresholding\n",
    "\n",
    "\n",
    "\n",
    "### Sudoku Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "22950844",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"../DATA/crossword.jpg\",0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "da9d0e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pic(img):\n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(img,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6136d591",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_pic(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ed69e6",
   "metadata": {},
   "source": [
    "## Simple Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68da6d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,th1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a61102",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_pic(th1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16570679",
   "metadata": {},
   "source": [
    "### Adaptive Threshold\n",
    "\n",
    "https://stackoverflow.com/questions/28763419/adaptive-threshold-parameters-confusion\n",
    "\n",
    "    @param src Source 8-bit single-channel image.\n",
    "    .   @param dst Destination image of the same size and the same type as src.\n",
    "    .   @param maxValue Non-zero value assigned to the pixels for which the condition is satisfied\n",
    "    .   @param adaptiveMethod Adaptive thresholding algorithm to use, see #AdaptiveThresholdTypes.\n",
    "    .   The #BORDER_REPLICATE | #BORDER_ISOLATED is used to process boundaries.\n",
    "    .   @param thresholdType Thresholding type that must be either #THRESH_BINARY or #THRESH_BINARY_INV,\n",
    "    .   see #ThresholdTypes.\n",
    "    .   @param blockSize Size of a pixel neighborhood that is used to calculate a threshold value for the\n",
    "    .   pixel: 3, 5, 7, and so on.\n",
    "    .   @param C Constant subtracted from the mean or weighted mean (see the details below). Normally, it\n",
    "    .   is positive but may be zero or negative as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a98293",
   "metadata": {},
   "outputs": [],
   "source": [
    "th2 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11,8) # Play around with these last 2 numbers\n",
    "show_pic(th2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778b0c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "th3 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,15,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5867cc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_pic(th3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090ded25",
   "metadata": {},
   "outputs": [],
   "source": [
    "blended = cv2.addWeighted(src1=th1,alpha=0.7,src2=th2,beta=0.3,gamma=0)\n",
    "show_pic(blended)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016c2aec",
   "metadata": {},
   "source": [
    "# Blurring and Smoothing\n",
    "\n",
    "There are a lot of different effects and filters we can apply to images. We're just going to go through a few of them here. Most of them involve some sort of math based function being applied to all the pixels values.\n",
    "\n",
    "\n",
    "-----\n",
    "#### Info Link on Blurring Math:\n",
    "\n",
    "http://people.csail.mit.edu/sparis/bf_course/\n",
    "\n",
    "------\n",
    "\n",
    "## Convenience Functions\n",
    "\n",
    "Quick function for loading the puppy image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a04978f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a5ba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img():\n",
    "    img = cv2.imread('../DATA/bricks.jpg').astype(np.float32) / 255\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff571c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_img(img):\n",
    "    fig = plt.figure(figsize=(12,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc44f02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = load_img()\n",
    "display_img(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85882d2",
   "metadata": {},
   "source": [
    "### Gamma Correction : Practical Effect of Increasing Brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb1a0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img()\n",
    "gamma = 1/4\n",
    "effected_image = np.power(img, gamma)\n",
    "display_img(effected_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4094df",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img()\n",
    "gamma = 2\n",
    "effected_image = np.power(img, gamma)\n",
    "display_img(effected_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac2ab4d",
   "metadata": {},
   "source": [
    "### Low Pass Filter with a 2D Convolution\n",
    "\n",
    "A fitlering operation known as 2D convolution can be used to create a low-pass filter. Make sure to view the video for an explanation of what's happening in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77285033",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img()\n",
    "font = cv2.FONT_HERSHEY_COMPLEX\n",
    "cv2.putText(img,text='bricks',org=(10,600), fontFace=font,fontScale= 10,color=(255,0,0),thickness=4)\n",
    "display_img(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f188ea",
   "metadata": {},
   "source": [
    "### Create the Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45138827",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones(shape=(5,5),dtype=np.float32)/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2679e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7ceeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = cv2.filter2D(img,-1,kernel)\n",
    "display_img(dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4008de4b",
   "metadata": {},
   "source": [
    "## Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d5603a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img()\n",
    "font = cv2.FONT_HERSHEY_COMPLEX\n",
    "cv2.putText(img,text='bricks',org=(10,600), fontFace=font,fontScale= 10,color=(255,0,0),thickness=4)\n",
    "display_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a2bbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred_img = cv2.blur(img,ksize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13fb2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_img(blurred_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf6c856",
   "metadata": {},
   "source": [
    "## Gaussian Blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e555cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img()\n",
    "font = cv2.FONT_HERSHEY_COMPLEX\n",
    "cv2.putText(img,text='bricks',org=(10,600), fontFace=font,fontScale= 10,color=(255,0,0),thickness=4)\n",
    "display_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856233f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred_img = cv2.GaussianBlur(img,(5,5),10)\n",
    "display_img(blurred_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5385f8e1",
   "metadata": {},
   "source": [
    "## Median Blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dd25b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img()\n",
    "font = cv2.FONT_HERSHEY_COMPLEX\n",
    "cv2.putText(img,text='bricks',org=(10,600), fontFace=font,fontScale= 10,color=(255,0,0),thickness=4)\n",
    "display_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292863b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "median = cv2.medianBlur(img,5)\n",
    "display_img(median)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67af11bf",
   "metadata": {},
   "source": [
    "----------\n",
    "### Adding Noise\n",
    "\n",
    "Let's see a more useful case of Median Blurring by adding some random noise to an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb14921",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../DATA/sammy.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592eac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ee8749",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff27c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afed84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84118fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beb5dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_img = cv2.imread('../DATA/sammy_noise.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4f8faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_img(noise_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f2b23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "median = cv2.medianBlur(noise_img,5)\n",
    "display_img(median)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b9cb19",
   "metadata": {},
   "source": [
    "## Bilateral Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26c0f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img()\n",
    "font = cv2.FONT_HERSHEY_COMPLEX\n",
    "cv2.putText(img,text='bricks',org=(10,600), fontFace=font,fontScale= 10,color=(255,0,0),thickness=4)\n",
    "display_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1c34b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "blur = cv2.bilateralFilter(img,9,75,75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e835e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_img(blur)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30e4639",
   "metadata": {},
   "source": [
    "# Morphological Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3aa2abb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img():\n",
    "    blank_img =np.zeros((600,600))\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(blank_img,text='ABCDE',org=(50,300), fontFace=font,fontScale= 5,color=(255,255,255),thickness=25,lineType=cv2.LINE_AA)\n",
    "    return blank_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e6e229e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_img(img):\n",
    "    fig = plt.figure(figsize=(12,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(img,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7c4a3e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073cd396",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_img(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f306a9fa",
   "metadata": {},
   "source": [
    "## Erosion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0465547c",
   "metadata": {},
   "source": [
    "Erodes away boundaries of foreground objects. Works best when foreground is light color (preferrably white) and background is dark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7efdcaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((5,5),np.uint8)\n",
    "erosion1 = cv2.erode(img,kernel,iterations = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ed66b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_img(erosion1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f09596f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img()\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "erosion5 = cv2.erode(img,kernel,iterations = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9135a2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_img(erosion5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa1564c",
   "metadata": {},
   "source": [
    "## Opening\n",
    "Opening is erosion followed by dilation. Useful in removing background noise!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f2bccd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2aa5c8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_noise = np.random.randint(low=0,high=2,size=(600,600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec7b976",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "dc9c7eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_noise = white_noise*255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d10fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bdb7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "332aaeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_img = white_noise+img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544adf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_img(noise_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a441159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "opening = cv2.morphologyEx(noise_img, cv2.MORPH_OPEN, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28302953",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_img(opening)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2029f3a",
   "metadata": {},
   "source": [
    "### Closing\n",
    " Useful in removing noise from foreground objects, such as black dots on top of the white text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cb3d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e6b82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_noise = np.random.randint(low=0,high=2,size=(600,600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e278ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cd6e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_noise= black_noise * -255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ad4a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_noise_img = img + black_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fd76ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_noise_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0151226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_noise_img[black_noise_img==-255] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bc6d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_img(black_noise_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96ef4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "closing = cv2.morphologyEx(black_noise_img, cv2.MORPH_CLOSE, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307b93ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_img(closing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d51fd0b",
   "metadata": {},
   "source": [
    "## Morphological Gradient\n",
    "\n",
    "Difference between dilation and erosion of an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb6957b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084bb329",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef12871",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient = cv2.morphologyEx(img,cv2.MORPH_GRADIENT,kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f40292",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_img(gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74a4ea7",
   "metadata": {},
   "source": [
    "# Gradients\n",
    "\n",
    "Understanding gradients will allow us to eventually understand edge detection which we will use later on, since its an important aspect of object detection in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c285b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../DATA/sudoku.jpg',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345c2342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_img(img):\n",
    "    fig = plt.figure(figsize=(12,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(img,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a96955",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7295d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)\n",
    "sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5)\n",
    "laplacian = cv2.Laplacian(img,cv2.CV_64F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a3c73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_img(sobelx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4df4de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_img(sobely)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84e85a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_img(laplacian)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760b6472",
   "metadata": {},
   "source": [
    "## Combining Previous Ideas\n",
    "\n",
    "Let's play around with these images with some of the other ideas we've already seen!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2c8fe7",
   "metadata": {},
   "source": [
    "### Blending Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a78611",
   "metadata": {},
   "outputs": [],
   "source": [
    "blended = cv2.addWeighted(src1=sobelx,alpha=0.5,src2=sobely,beta=0.5,gamma=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f237d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_img(blended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80eb615",
   "metadata": {},
   "outputs": [],
   "source": [
    "blended.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3153e4",
   "metadata": {},
   "source": [
    "### Morphological Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be55a18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((4,4),np.uint8)\n",
    "gradient = cv2.morphologyEx(blended,cv2.MORPH_GRADIENT,kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d842e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_img(gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9262211",
   "metadata": {},
   "source": [
    "Try it on the laplacian result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4787e974",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((3,3),np.uint8)\n",
    "gradient = cv2.morphologyEx(blended,cv2.MORPH_GRADIENT,kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a454d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_img(gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5be31d",
   "metadata": {},
   "source": [
    "### Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27b1d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,th1 = cv2.threshold(img,100,255,cv2.THRESH_BINARY)\n",
    "display_img(th1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98f281b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,th1 = cv2.threshold(gradient,200,255,cv2.THRESH_BINARY_INV)\n",
    "display_img(th1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22ca990",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,th1 = cv2.threshold(blended,100,255,cv2.THRESH_BINARY_INV)\n",
    "display_img(th1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ede270b",
   "metadata": {},
   "source": [
    "# Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1552b41d",
   "metadata": {},
   "source": [
    "## Image Histograms with OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6338eed7",
   "metadata": {},
   "source": [
    "Recall that Matplotlib expects the images in a different RGB ordering vs BGR in OpenCV, so if we use OpenCV to calculate anything channel oriented, we'll want to make sure we keep the original RGB ordering, however if we ever want to display the image, then we'll need to convert to the RGB ordering that matplotlib wants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893598f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dark_horse = cv2.imread('../DATA/horse.jpg')\n",
    "show_horse = cv2.cvtColor(dark_horse, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "rainbow = cv2.imread('../DATA/rainbow.jpg')\n",
    "show_rainbow =cv2.cvtColor(rainbow, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "blue_bricks = cv2.imread('../DATA/bricks.jpg')\n",
    "show_bricks = cv2.cvtColor(blue_bricks, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639d1e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(show_horse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e43cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECALL MATPLOTLIB IMSHOW EXPECTS THE RGB IN A DIFFERENT ORDER!\n",
    "\n",
    "plt.imshow(dark_horse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d37876",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(show_rainbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db05ea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(show_bricks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27b20da",
   "metadata": {},
   "source": [
    "### OpenCV Histogram\n",
    "\n",
    "**cv2.calcHist(images, channels, mask, histSize, ranges[, hist[, accumulate]])**\n",
    "\n",
    "* images : it is the source image of type uint8 or float32. it should be given in square brackets, ie, “[img]”.\n",
    "* channels : it is also given in square brackets. It is the index of channel for which we calculate histogram. For example, if input is grayscale image, its value is [0]. For color image, you can pass [0], [1] or [2] to calculate histogram of blue, green or red channel respectively.\n",
    "* mask : mask image. To find histogram of full image, it is given as “None”. But if you want to find histogram of particular region of image, you have to create a mask image for that and give it as mask. (I will show an example later.)\n",
    "* histSize : this represents our BIN count. Need to be given in square brackets. For full scale, we pass [256].\n",
    "* ranges : this is our RANGE. Normally, it is [0,256]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe991850",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_values = cv2.calcHist([blue_bricks],channels=[0],mask=None,histSize=[256],ranges=[0,256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d06c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c987a719",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d00892d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_values = cv2.calcHist([dark_horse],channels=[0],mask=None,histSize=[256],ranges=[0,256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0c5e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee182ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(show_horse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f60086",
   "metadata": {},
   "source": [
    "## Plotting 3 Color Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef75b895",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = blue_bricks\n",
    "color = ('b','g','r')\n",
    "for i,col in enumerate(color):\n",
    "    histr = cv2.calcHist([img],[i],None,[256],[0,256])\n",
    "    plt.plot(histr,color = col)\n",
    "    plt.xlim([0,256])\n",
    "plt.title('Blue Bricks Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b372d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = dark_horse\n",
    "color = ('b','g','r')\n",
    "for i,col in enumerate(color):\n",
    "    histr = cv2.calcHist([img],[i],None,[256],[0,256])\n",
    "    plt.plot(histr,color = col)\n",
    "    plt.xlim([0,256])\n",
    "plt.title('Dark Horse')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0f25c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = rainbow\n",
    "color = ('b','g','r')\n",
    "for i,col in enumerate(color):\n",
    "    histr = cv2.calcHist([img],[i],None,[256],[0,256])\n",
    "    plt.plot(histr,color = col)\n",
    "    plt.xlim([0,256])\n",
    "plt.title('Rainbow Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaf9844",
   "metadata": {},
   "source": [
    "### Masking\n",
    "\n",
    "We can mask only certain parts of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba589415",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = rainbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b4d950",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ac44c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mask\n",
    "mask = np.zeros(img.shape[:2], np.uint8)\n",
    "mask[300:400, 100:400] = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c85bb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc97eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_img = cv2.bitwise_and(img,img,mask = mask)\n",
    "show_masked_img = cv2.bitwise_and(show_rainbow,show_rainbow,mask = mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37f0384",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(show_masked_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c316fee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_mask_values_red = cv2.calcHist([rainbow],channels=[2],mask=mask,histSize=[256],ranges=[0,256])\n",
    "hist_full_values_red = cv2.calcHist([rainbow],channels=[2],mask=None,histSize=[256],ranges=[0,256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ea65cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist_full_values_red)\n",
    "plt.title('Histogram for RED values of the full image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d75ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist_mask_values_red)\n",
    "plt.title('Histogram for RED values for the Masked Area')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16940451",
   "metadata": {},
   "source": [
    "# Histogram Equalization\n",
    "https://en.wikipedia.org/wiki/Histogram_equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e79268",
   "metadata": {},
   "outputs": [],
   "source": [
    "gorilla = cv2.imread('../DATA/gorilla.jpg',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cc5df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(img,cmap=None):\n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(img,cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48bac26",
   "metadata": {},
   "source": [
    "## Single Channel (Grayscale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00ce7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(gorilla,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd99e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_values = cv2.calcHist([gorilla],channels=[0],mask=None,histSize=[256],ranges=[0,256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9888131",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae5be10",
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_gorilla = cv2.equalizeHist(gorilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479664f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(eq_gorilla,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e95235",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_values = cv2.calcHist([eq_gorilla],channels=[0],mask=None,histSize=[256],ranges=[0,256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8b86b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382d84a9",
   "metadata": {},
   "source": [
    "## Color Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909e57aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_gorilla = cv2.imread('../DATA/gorilla.jpg')\n",
    "show_gorilla = cv2.cvtColor(color_gorilla,cv2.COLOR_BGR2RGB)\n",
    "# Convert to HSV colorspace\n",
    "hsv = cv2.cvtColor(color_gorilla, cv2.COLOR_BGR2HSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b367f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(show_gorilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59f9011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab V channel\n",
    "hsv[:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3a54fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv[:,:,2] = cv2.equalizeHist(hsv[:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db24de49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert back to RGB to visualize\n",
    "eq_color_gorilla = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "display(eq_color_gorilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90e23fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
